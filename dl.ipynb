{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b42af067",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LSTM, GRU, Conv1D, GlobalMaxPooling1D, Input, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fd86e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Configuration\n",
    "RANDOM_STATE = 42\n",
    "LSA_COMPONENTS = 100\n",
    "tf.random.set_seed(RANDOM_STATE)\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# D√©finir le chemin de base\n",
    "base = r\"C:\\Users\\hp\\Desktop\\pfemaster\\vectors\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df08d82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = r\"C:\\Users\\hp\\Desktop\\pfemaster\\vectors\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ebfc3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Vecteurs charg√©s avec succ√®s!\n",
      "üìä Formes des donn√©es:\n",
      "   TF-IDF: (19761, 5652)\n",
      "   GloVe: (19761, 200)\n",
      "   Word2Vec: (19761, 100)\n",
      "   BERT: (19761, 768)\n",
      "   BERT_2: (19761, 768)\n"
     ]
    }
   ],
   "source": [
    "# Chargement des 5 types de vecteurs\n",
    "X_train_tfidf = joblib.load(base + \"/X_train_tfidf.pkl\")\n",
    "X_test_tfidf = joblib.load(base + \"/X_test_tfidf.pkl\")\n",
    "\n",
    "X_train_glove = joblib.load(base + \"/X_train_glove.pkl\")\n",
    "X_test_glove = joblib.load(base + \"/X_test_glove.pkl\")\n",
    "\n",
    "X_train_w2v = joblib.load(base + \"/X_train_w2v.pkl\")\n",
    "X_test_w2v = joblib.load(base + \"/X_test_w2v.pkl\")\n",
    "\n",
    "X_train_bert = joblib.load(base + \"/X_train_bert.pkl\")\n",
    "X_test_bert = joblib.load(base + \"/X_test_bert.pkl\")\n",
    "\n",
    "X_train_bert_2 = joblib.load(base + \"/X_train_bert_2.pkl\")\n",
    "X_test_bert_2 = joblib.load(base + \"/X_test_bert_2.pkl\")\n",
    "\n",
    "y_train = joblib.load(base + \"/y_train.pkl\")\n",
    "y_test = joblib.load(base + \"/y_test.pkl\")\n",
    "\n",
    "print(\"‚úÖ Vecteurs charg√©s avec succ√®s!\")\n",
    "print(f\"üìä Formes des donn√©es:\")\n",
    "print(f\"   TF-IDF: {X_train_tfidf.shape}\")\n",
    "print(f\"   GloVe: {X_train_glove.shape}\")\n",
    "print(f\"   Word2Vec: {X_train_w2v.shape}\")\n",
    "print(f\"   BERT: {X_train_bert.shape}\")\n",
    "print(f\"   BERT_2: {X_train_bert_2.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e636040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Nombre de classes: 3\n"
     ]
    }
   ],
   "source": [
    "# Encoder les labels si n√©cessaire\n",
    "label_encoder = LabelEncoder()\n",
    "if y_train.dtype == 'object' or isinstance(y_train[0], str):\n",
    "    y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "    y_test_encoded = label_encoder.transform(y_test)\n",
    "else:\n",
    "    y_train_encoded = y_train\n",
    "    y_test_encoded = y_test\n",
    "\n",
    "# Conversion en format cat√©goriel pour Keras\n",
    "num_classes = len(np.unique(y_train_encoded))\n",
    "y_train_categorical = to_categorical(y_train_encoded, num_classes)\n",
    "y_test_categorical = to_categorical(y_test_encoded, num_classes)\n",
    "\n",
    "print(f\"üéØ Nombre de classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80656f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üî¨ Application de LSA sur chaque type de vecteur...\n",
      "\n",
      "üìà Traitement du groupe SPARSE...\n",
      "   üîß tfidf...\n",
      "      ‚úÖ (19761, 5652) ‚Üí (19761, 100) (Variance: 0.051)\n",
      "\n",
      "üìà Traitement du groupe DENSE_SEMANTIC...\n",
      "   üîß glove...\n",
      "      ‚úÖ (19761, 200) ‚Üí (19761, 100) (Variance: 1.000)\n",
      "   üîß w2v...\n",
      "      ‚úÖ (19761, 100) ‚Üí (19761, 99) (Variance: 1.000)\n",
      "\n",
      "üìà Traitement du groupe CONTEXTUAL...\n",
      "   üîß bert...\n",
      "      ‚úÖ (19761, 768) ‚Üí (19761, 100) (Variance: 0.810)\n",
      "   üîß bert_2...\n",
      "      ‚úÖ (19761, 768) ‚Üí (19761, 100) (Variance: 0.838)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nüî¨ Application de LSA sur chaque type de vecteur...\")\n",
    "\n",
    "# Classification des vecteurs par type\n",
    "vector_groups = {\n",
    "    'sparse': {  # Vecteurs creux (TF-IDF)\n",
    "        'tfidf': (X_train_tfidf, X_test_tfidf)\n",
    "    },\n",
    "    'dense_semantic': {  # Vecteurs denses s√©mantiques (GloVe, Word2Vec)\n",
    "        'glove': (X_train_glove, X_test_glove),\n",
    "        'w2v': (X_train_w2v, X_test_w2v)\n",
    "    },\n",
    "    'contextual': {  # Vecteurs contextuels (BERT)\n",
    "        'bert': (X_train_bert, X_test_bert),\n",
    "        'bert_2': (X_train_bert_2, X_test_bert_2)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Application de LSA\n",
    "lsa_vectors = {}\n",
    "lsa_models = {}\n",
    "scalers = {}\n",
    "\n",
    "for group_name, vectors in vector_groups.items():\n",
    "    print(f\"\\nüìà Traitement du groupe {group_name.upper()}...\")\n",
    "    \n",
    "    for vector_name, (X_train_vec, X_test_vec) in vectors.items():\n",
    "        print(f\"   üîß {vector_name}...\")\n",
    "        \n",
    "        # Normalisation\n",
    "        scaler = StandardScaler(with_mean=False)\n",
    "        X_train_scaled = scaler.fit_transform(X_train_vec)\n",
    "        X_test_scaled = scaler.transform(X_test_vec)\n",
    "        \n",
    "        # LSA\n",
    "        n_components = min(LSA_COMPONENTS, X_train_scaled.shape[1] - 1, X_train_scaled.shape[0] - 1)\n",
    "        lsa = TruncatedSVD(n_components=n_components, random_state=RANDOM_STATE)\n",
    "        \n",
    "        X_train_lsa = lsa.fit_transform(X_train_scaled)\n",
    "        X_test_lsa = lsa.transform(X_test_scaled)\n",
    "        \n",
    "        # Stockage\n",
    "        lsa_vectors[vector_name] = (X_train_lsa, X_test_lsa)\n",
    "        lsa_models[vector_name] = lsa\n",
    "        scalers[vector_name] = scaler\n",
    "        \n",
    "        print(f\"      ‚úÖ {X_train_vec.shape} ‚Üí {X_train_lsa.shape} (Variance: {lsa.explained_variance_ratio_.sum():.3f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88d87176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tfidf': (array([[ 2.23469913, -0.64039804, -0.43979426, ...,  1.74200915,\n",
       "           2.5145644 , -0.21865849],\n",
       "         [ 5.8699267 , -1.360717  , -1.41432682, ..., -2.03540259,\n",
       "          -1.6963573 ,  2.75632047],\n",
       "         [ 1.11960352, -0.33207204, -0.32606331, ...,  0.28882977,\n",
       "           0.68983079, -0.81725554],\n",
       "         ...,\n",
       "         [ 3.93307214, -0.91527615, -0.66050729, ...,  4.9889652 ,\n",
       "           0.99237451,  0.94330494],\n",
       "         [ 6.05106477, -1.60807885, -1.25036167, ..., -3.54361996,\n",
       "          -3.03254568,  0.68577112],\n",
       "         [ 4.67046625, -1.35843604, -0.87385672, ..., -0.01132244,\n",
       "           1.84704299, -3.10726446]]),\n",
       "  array([[ 3.63964694, -1.0873039 , -0.93271179, ..., -2.56212152,\n",
       "          -0.68378169, -1.95270867],\n",
       "         [ 4.50607613, -1.2755259 , -1.02979365, ...,  0.87116447,\n",
       "           1.30246021,  0.15376164],\n",
       "         [ 1.25633186, -0.35893548, -0.33464438, ..., -0.20325232,\n",
       "          -0.92947489,  0.76007339],\n",
       "         ...,\n",
       "         [ 1.88154635, -0.52518436, -0.40220517, ...,  2.04896537,\n",
       "          -0.12441446,  0.31262882],\n",
       "         [ 1.87022024, -0.32811559, -0.3310291 , ..., -0.92960765,\n",
       "          -0.06917755,  0.30822543],\n",
       "         [ 1.74197709, -0.52424509, -0.4926884 , ...,  0.19032536,\n",
       "           0.01748394,  0.09916865]])),\n",
       " 'glove': (array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         ...,\n",
       "         [-3.14437023e+01,  2.40259042e+01,  2.78877508e+00, ...,\n",
       "          -2.49040688e-16, -2.98285588e-15, -2.19390506e-15],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]),\n",
       "  array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]])),\n",
       " 'w2v': (array([[-9.72569499e+00,  1.36226621e+00,  3.92315262e-01, ...,\n",
       "          -2.16500998e-02,  3.20462813e-03,  4.81011927e-03],\n",
       "         [-9.93473940e+00,  1.01942597e+00, -3.11774625e-02, ...,\n",
       "           4.02480651e-03, -9.59845235e-03, -3.73562499e-03],\n",
       "         [-1.25961973e+01,  1.61801042e+00, -8.63080416e-02, ...,\n",
       "           5.27408444e-03,  5.37513379e-03, -2.95279754e-02],\n",
       "         ...,\n",
       "         [-1.86107174e+01, -1.91593582e+00,  3.79026360e-01, ...,\n",
       "          -1.20876264e-02,  2.09791246e-02, -1.35612665e-02],\n",
       "         [-2.14638331e+01,  6.65620174e-01,  6.03600558e-02, ...,\n",
       "           9.05192851e-03, -6.16087601e-03,  1.98901552e-03],\n",
       "         [-6.55960511e+00,  4.93702551e-01, -5.49056402e-02, ...,\n",
       "          -7.07197880e-03,  9.31945288e-03, -7.99147941e-03]]),\n",
       "  array([[-2.94338487e+01,  4.36833955e+00,  1.13554414e-01, ...,\n",
       "           1.86175919e-03, -3.59291824e-03, -1.86419848e-02],\n",
       "         [-2.08698528e+01,  2.35961158e+00,  2.88030327e-01, ...,\n",
       "           1.25796107e-02, -1.32619540e-03, -8.81372683e-03],\n",
       "         [-2.56850107e+01,  3.35644095e+00, -2.77261187e-01, ...,\n",
       "          -1.34787025e-02, -2.89198548e-02,  1.83563183e-02],\n",
       "         ...,\n",
       "         [-1.17482495e+01,  7.81806046e-01, -5.70491942e-02, ...,\n",
       "           7.23607623e-03, -1.01723827e-02, -1.35990616e-02],\n",
       "         [-8.40540655e+00, -8.15852349e-02, -5.96478938e-02, ...,\n",
       "           2.69742088e-02,  1.10463510e-02,  2.23328168e-02],\n",
       "         [-9.04214782e+00,  1.16229286e+00, -1.62388650e-01, ...,\n",
       "           2.25095333e-03, -1.15541351e-02,  2.51602080e-02]])),\n",
       " 'bert': (array([[ 28.421295  ,   4.6643696 , -11.98869   , ...,   0.7187886 ,\n",
       "           -0.11538291,  -0.55304754],\n",
       "         [ 11.471319  ,  14.302113  ,   1.3267843 , ...,  -0.78048176,\n",
       "            0.21577668,  -1.2434255 ],\n",
       "         [ 27.315294  ,   8.105198  ,   1.0557177 , ...,  -2.5157819 ,\n",
       "           -2.4766567 ,   2.2486167 ],\n",
       "         ...,\n",
       "         [ 19.855618  ,  15.135151  , -17.18306   , ...,  -1.5069158 ,\n",
       "           -0.25752628,   0.47563028],\n",
       "         [  8.678837  ,  12.968315  ,   3.378151  , ...,   0.36342308,\n",
       "           -0.5599007 ,   0.28459424],\n",
       "         [ 14.359167  ,  16.347715  ,   6.2392373 , ...,   0.18120798,\n",
       "            1.4261825 ,   0.9574267 ]], dtype=float32),\n",
       "  array([[ 2.1191444e+01, -1.4637058e+01, -7.8093367e+00, ...,\n",
       "          -2.2478054e-01, -9.3968588e-01, -8.7768823e-01],\n",
       "         [ 2.5290270e+01,  1.2301667e+01, -1.2446310e+01, ...,\n",
       "          -1.2609696e+00,  3.7205184e-01,  1.4899817e+00],\n",
       "         [ 2.3852434e+01,  4.8407860e+00,  1.2323959e+01, ...,\n",
       "          -1.2946358e-01, -3.8169651e+00,  2.3062706e-02],\n",
       "         ...,\n",
       "         [ 1.5210659e+01,  8.8725710e+00,  5.1337242e+00, ...,\n",
       "          -1.4501052e+00,  1.4607977e+00, -8.1213176e-02],\n",
       "         [ 2.7675682e+01,  6.8649249e+00, -6.3530240e+00, ...,\n",
       "          -1.9536420e+00, -1.3607550e+00,  2.6006491e+00],\n",
       "         [ 2.6717903e+01,  8.1554890e+00,  5.8938313e+00, ...,\n",
       "          -4.6087492e-01, -2.1455495e+00,  1.7156637e+00]], dtype=float32)),\n",
       " 'bert_2': (array([[ 5.61651325e+00,  2.11238060e+01,  5.25501156e+00, ...,\n",
       "          -6.18687451e-01, -6.82443261e-01, -4.13881123e-01],\n",
       "         [ 3.80545974e+00,  4.10277224e+00, -1.78281116e+01, ...,\n",
       "          -1.53782725e-01, -1.15657151e-02, -5.38392901e-01],\n",
       "         [ 3.02113318e+00,  7.44033337e+00, -1.57781105e+01, ...,\n",
       "           1.25941265e+00,  7.83095479e-01,  1.46106982e+00],\n",
       "         ...,\n",
       "         [ 4.89702129e+00,  2.00716858e+01,  4.28020287e+00, ...,\n",
       "           1.13478804e+00, -7.20015526e-01,  1.03205657e+00],\n",
       "         [ 3.05545759e+00,  5.27312565e+00, -1.59557381e+01, ...,\n",
       "           6.37767673e-01, -9.95718837e-02, -5.12348264e-02],\n",
       "         [ 3.24293861e+01, -4.45213366e+00,  1.26359046e+00, ...,\n",
       "          -3.93368244e-01, -1.33081853e-01,  9.34190378e-02]], dtype=float32),\n",
       "  array([[  6.3737783 ,  18.805916  ,   5.431118  , ...,  -0.12179813,\n",
       "            1.1565131 ,   1.5795774 ],\n",
       "         [  3.925272  ,   4.9724827 , -16.949663  , ...,  -0.70998305,\n",
       "            0.16984412,  -0.6112032 ],\n",
       "         [ -0.32554436,  -0.08519614,   0.14662033, ...,  -1.4877914 ,\n",
       "            1.6842062 ,   2.3836434 ],\n",
       "         ...,\n",
       "         [ -0.49651873,  -0.4806406 ,  -0.20236778, ...,  -1.6989654 ,\n",
       "            1.847514  ,   2.509925  ],\n",
       "         [  4.0641546 ,   6.2404256 , -16.345795  , ...,   0.11467884,\n",
       "           -3.45813   ,   1.8312526 ],\n",
       "         [  4.400932  ,   6.1631565 , -15.104162  , ...,   0.55773336,\n",
       "            1.2705836 ,   1.2446125 ]], dtype=float32))}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a286f3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß† D√âFINITION DES 3 MOD√àLES DEEP LEARNING SP√âCIALIS√âS\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nüß† D√âFINITION DES 3 MOD√àLES DEEP LEARNING SP√âCIALIS√âS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def create_sparse_model(input_dim, num_classes):\n",
    "    \"\"\"\n",
    "    MOD√àLE 1: DNN CLASSIQUE pour vecteurs creux (TF-IDF)\n",
    "    \n",
    "    POURQUOI CE MOD√àLE ?\n",
    "    - Les vecteurs TF-IDF sont creux et de haute dimension\n",
    "    - Un DNN classique avec dropout √©lev√© g√®re bien la sparsit√©\n",
    "    - BatchNormalization aide √† stabiliser l'entra√Ænement\n",
    "    - Architecture profonde pour capturer les patterns complexes\n",
    "    \"\"\"\n",
    "    print(\"üîß MOD√àLE 1 - DNN CLASSIQUE (pour TF-IDF)\")\n",
    "    print(\"   üí° Optimis√© pour: vecteurs creux, haute dimension\")\n",
    "    print(\"   üéØ Avantages: gestion sparsit√©, dropout √©lev√©, stabilit√©\")\n",
    "    \n",
    "    model = Sequential([\n",
    "        Dense(1024, activation='relu', input_shape=(input_dim,)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),  # Dropout √©lev√© pour la sparsit√©\n",
    "        \n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "        \n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ], name='Sparse_DNN')\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "785cebcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_semantic_model(input_dim, num_classes):\n",
    "    \"\"\"\n",
    "    MOD√àLE 2: CNN-LSTM HYBRIDE pour vecteurs s√©mantiques (GloVe, Word2Vec)\n",
    "    \n",
    "    POURQUOI CE MOD√àLE ?\n",
    "    - Les vecteurs GloVe/Word2Vec capturent des relations s√©mantiques\n",
    "    - CNN extrait des features locales (n-grammes s√©mantiques)\n",
    "    - LSTM capture les d√©pendances s√©quentielles\n",
    "    - Combinaison optimale pour la richesse s√©mantique\n",
    "    \"\"\"\n",
    "    print(\"üîß MOD√àLE 2 - CNN-LSTM HYBRIDE (pour GloVe, Word2Vec)\")\n",
    "    print(\"   üí° Optimis√© pour: relations s√©mantiques, patterns s√©quentiels\")\n",
    "    print(\"   üéØ Avantages: features locales + d√©pendances temporelles\")\n",
    "    \n",
    "    # Reshaper les donn√©es pour CNN-LSTM\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    \n",
    "    # Expansion pour CNN (simulation de s√©quence)\n",
    "    reshaped = Reshape((input_dim, 1))(input_layer)\n",
    "    \n",
    "    # Couches CNN pour features locales\n",
    "    conv1 = Conv1D(128, 3, activation='relu', padding='same')(reshaped)\n",
    "    conv1 = Dropout(0.3)(conv1)\n",
    "    \n",
    "    conv2 = Conv1D(64, 3, activation='relu', padding='same')(conv1)\n",
    "    conv2 = Dropout(0.3)(conv2)\n",
    "    \n",
    "    # Couche LSTM pour d√©pendances s√©quentielles\n",
    "    lstm = LSTM(64, return_sequences=False)(conv2)\n",
    "    lstm = Dropout(0.3)(lstm)\n",
    "    \n",
    "    # Couches denses finales\n",
    "    dense1 = Dense(128, activation='relu')(lstm)\n",
    "    dense1 = BatchNormalization()(dense1)\n",
    "    dense1 = Dropout(0.2)(dense1)\n",
    "    \n",
    "    dense2 = Dense(64, activation='relu')(dense1)\n",
    "    dense2 = Dropout(0.2)(dense2)\n",
    "    \n",
    "    output = Dense(num_classes, activation='softmax')(dense2)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output, name='Semantic_CNN_LSTM')\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.0005),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d0dc7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_contextual_model(input_dim, num_classes):\n",
    "    \"\"\"\n",
    "    MOD√àLE 3: ATTENTION-BASED DEEP NETWORK pour vecteurs contextuels (BERT)\n",
    "    \n",
    "    POURQUOI CE MOD√àLE ?\n",
    "    - Les vecteurs BERT sont contextuels et de haute qualit√©\n",
    "    - M√©canisme d'attention pour identifier les features importantes\n",
    "    - Architecture plus complexe pour exploiter la richesse contextuelle\n",
    "    - Residual connections pour pr√©server l'information\n",
    "    \"\"\"\n",
    "    print(\"üîß MOD√àLE 3 - ATTENTION-BASED NETWORK (pour BERT)\")\n",
    "    print(\"   üí° Optimis√© pour: repr√©sentations contextuelles, attention\")\n",
    "    print(\"   üéØ Avantages: m√©canisme attention, residual connections\")\n",
    "    \n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    \n",
    "    # Premi√®re branche - Attention mechanism simul√©\n",
    "    attention_weights = Dense(input_dim, activation='sigmoid', name='attention_weights')(input_layer)\n",
    "    attended_features = tf.multiply(input_layer, attention_weights)\n",
    "    \n",
    "    # Deuxi√®me branche - Transformation directe\n",
    "    direct_features = Dense(input_dim, activation='relu')(input_layer)\n",
    "    \n",
    "    # Fusion des branches\n",
    "    combined = Concatenate()([attended_features, direct_features])\n",
    "    combined = BatchNormalization()(combined)\n",
    "    combined = Dropout(0.3)(combined)\n",
    "    \n",
    "    # Blocs r√©siduel-like\n",
    "    dense1 = Dense(512, activation='relu')(combined)\n",
    "    dense1 = BatchNormalization()(dense1)\n",
    "    dense1 = Dropout(0.3)(dense1)\n",
    "    \n",
    "    # Residual connection simul√©e\n",
    "    residual1 = Dense(512, activation='linear')(combined)\n",
    "    merged1 = tf.add(dense1, residual1)\n",
    "    merged1 = tf.nn.relu(merged1)\n",
    "    \n",
    "    dense2 = Dense(256, activation='relu')(merged1)\n",
    "    dense2 = BatchNormalization()(dense2)\n",
    "    dense2 = Dropout(0.2)(dense2)\n",
    "    \n",
    "    dense3 = Dense(128, activation='relu')(dense2)\n",
    "    dense3 = Dropout(0.2)(dense3)\n",
    "    \n",
    "    output = Dense(num_classes, activation='softmax')(dense3)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output, name='Contextual_Attention')\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.0003),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3787b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_contextual_model(input_dim, num_classes):\n",
    "    \"\"\"\n",
    "    MOD√àLE 3: ATTENTION-BASED DEEP NETWORK pour vecteurs contextuels (BERT)\n",
    "    \n",
    "    POURQUOI CE MOD√àLE ?\n",
    "    - Les vecteurs BERT sont contextuels et de haute qualit√©\n",
    "    - M√©canisme d'attention pour identifier les features importantes\n",
    "    - Architecture plus complexe pour exploiter la richesse contextuelle\n",
    "    - Residual connections pour pr√©server l'information\n",
    "    \"\"\"\n",
    "    print(\"üîß MOD√àLE 3 - ATTENTION-BASED NETWORK (pour BERT)\")\n",
    "    print(\"   üí° Optimis√© pour: repr√©sentations contextuelles, attention\")\n",
    "    print(\"   üéØ Avantages: m√©canisme attention, residual connections\")\n",
    "    \n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    \n",
    "    # Premi√®re branche - Attention mechanism simul√©\n",
    "    attention_weights = Dense(input_dim, activation='sigmoid', name='attention_weights')(input_layer)\n",
    "    attended_features = Multiply()([input_layer, attention_weights])  # Replace tf.multiply\n",
    "    \n",
    "    # Deuxi√®me branche - Transformation directe\n",
    "    direct_features = Dense(input_dim, activation='relu')(input_layer)\n",
    "    \n",
    "    # Fusion des branches\n",
    "    combined = Concatenate()([attended_features, direct_features])\n",
    "    combined = BatchNormalization()(combined)\n",
    "    combined = Dropout(0.3)(combined)\n",
    "    \n",
    "    # Blocs r√©siduel-like\n",
    "    dense1 = Dense(512, activation='relu')(combined)\n",
    "    dense1 = BatchNormalization()(dense1)\n",
    "    dense1 = Dropout(0.3)(dense1)\n",
    "    \n",
    "    # Residual connection simul√©e\n",
    "    residual1 = Dense(512, activation='linear')(combined)\n",
    "    merged1 = Add()([dense1, residual1])  # Replace tf.add\n",
    "    merged1 = ReLU()(merged1)  # Replace tf.nn.relu\n",
    "    \n",
    "    dense2 = Dense(256, activation='relu')(merged1)\n",
    "    dense2 = BatchNormalization()(dense2)\n",
    "    dense2 = Dropout(0.2)(dense2)\n",
    "    \n",
    "    dense3 = Dense(128, activation='relu')(dense2)\n",
    "    dense3 = Dropout(0.2)(dense3)\n",
    "    \n",
    "    output = Dense(num_classes, activation='softmax')(dense3)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output, name='Contextual_Attention')\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.0003),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e4bc2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ ASSIGNATION DES MOD√àLES AUX TYPES DE VECTEURS\n",
      "=======================================================\n",
      "üìã Assignation des mod√®les:\n",
      "      TFIDF ‚Üí SPARSE\n",
      "      GLOVE ‚Üí SEMANTIC\n",
      "        W2V ‚Üí SEMANTIC\n",
      "       BERT ‚Üí CONTEXTUAL\n",
      "     BERT_2 ‚Üí CONTEXTUAL\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"\\nüéØ ASSIGNATION DES MOD√àLES AUX TYPES DE VECTEURS\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# Mapping des vecteurs vers les mod√®les appropri√©s\n",
    "model_assignment = {\n",
    "    # Vecteurs creux ‚Üí DNN Classique\n",
    "    'tfidf': ('sparse', create_sparse_model),\n",
    "    \n",
    "    # Vecteurs s√©mantiques ‚Üí CNN-LSTM\n",
    "    'glove': ('semantic', create_semantic_model),\n",
    "    'w2v': ('semantic', create_semantic_model),\n",
    "    \n",
    "    # Vecteurs contextuels ‚Üí Attention-based\n",
    "    'bert': ('contextual', create_contextual_model),\n",
    "    'bert_2': ('contextual', create_contextual_model)\n",
    "}\n",
    "\n",
    "print(\"üìã Assignation des mod√®les:\")\n",
    "for vector_name, (model_type, _) in model_assignment.items():\n",
    "    print(f\"   {vector_name.upper():>8} ‚Üí {model_type.upper()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f32232c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Reshape\n",
    "from keras.layers import Multiply             # Pour Keras autonome\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Dense, Dropout, BatchNormalization, \n",
    "    Concatenate, Multiply, Add, ReLU\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c34628f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ ENTRA√éNEMENT DES MOD√àLES SP√âCIALIS√âS\n",
      "=============================================\n",
      "\n",
      "üéØ Entra√Ænement: TFIDF avec mod√®le SPARSE\n",
      "--------------------------------------------------\n",
      "üîß MOD√àLE 1 - DNN CLASSIQUE (pour TF-IDF)\n",
      "   üí° Optimis√© pour: vecteurs creux, haute dimension\n",
      "   üéØ Avantages: gestion sparsit√©, dropout √©lev√©, stabilit√©\n",
      "üìä Architecture: Sparse_DNN\n",
      "üìè Input shape: (19761, 100)\n",
      "üî¢ Param√®tres: 800,003\n",
      "Epoch 1/100\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.5952 - loss: 0.9667 - val_accuracy: 0.7498 - val_loss: 0.6143 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.7239 - loss: 0.6564 - val_accuracy: 0.7523 - val_loss: 0.6091 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 19ms/step - accuracy: 0.7436 - loss: 0.6172 - val_accuracy: 0.7577 - val_loss: 0.6024 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 20ms/step - accuracy: 0.7551 - loss: 0.5883 - val_accuracy: 0.7598 - val_loss: 0.5992 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 18ms/step - accuracy: 0.7593 - loss: 0.5717 - val_accuracy: 0.7590 - val_loss: 0.5960 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - accuracy: 0.7737 - loss: 0.5503 - val_accuracy: 0.7608 - val_loss: 0.5887 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - accuracy: 0.7753 - loss: 0.5326 - val_accuracy: 0.7608 - val_loss: 0.5890 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.7904 - loss: 0.5102 - val_accuracy: 0.7569 - val_loss: 0.5931 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - accuracy: 0.7950 - loss: 0.5004 - val_accuracy: 0.7656 - val_loss: 0.5775 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.7964 - loss: 0.4791 - val_accuracy: 0.7602 - val_loss: 0.5959 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 18ms/step - accuracy: 0.8018 - loss: 0.4653 - val_accuracy: 0.7668 - val_loss: 0.5871 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 18ms/step - accuracy: 0.8139 - loss: 0.4542 - val_accuracy: 0.7563 - val_loss: 0.5979 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - accuracy: 0.8223 - loss: 0.4299 - val_accuracy: 0.7624 - val_loss: 0.5917 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - accuracy: 0.8294 - loss: 0.4169 - val_accuracy: 0.7650 - val_loss: 0.6022 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - accuracy: 0.8352 - loss: 0.3995 - val_accuracy: 0.7557 - val_loss: 0.6152 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 21ms/step - accuracy: 0.8400 - loss: 0.3879 - val_accuracy: 0.7557 - val_loss: 0.6161 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - accuracy: 0.8556 - loss: 0.3557 - val_accuracy: 0.7563 - val_loss: 0.6240 - learning_rate: 2.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - accuracy: 0.8658 - loss: 0.3259 - val_accuracy: 0.7598 - val_loss: 0.6172 - learning_rate: 2.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 25ms/step - accuracy: 0.8793 - loss: 0.2988 - val_accuracy: 0.7513 - val_loss: 0.6316 - learning_rate: 2.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 23ms/step - accuracy: 0.8840 - loss: 0.2867 - val_accuracy: 0.7575 - val_loss: 0.6337 - learning_rate: 2.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - accuracy: 0.8849 - loss: 0.2840 - val_accuracy: 0.7494 - val_loss: 0.6354 - learning_rate: 2.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 20ms/step - accuracy: 0.8915 - loss: 0.2664 - val_accuracy: 0.7577 - val_loss: 0.6354 - learning_rate: 2.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 20ms/step - accuracy: 0.8947 - loss: 0.2629 - val_accuracy: 0.7511 - val_loss: 0.6529 - learning_rate: 2.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - accuracy: 0.8997 - loss: 0.2494 - val_accuracy: 0.7494 - val_loss: 0.6513 - learning_rate: 4.0000e-05\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'precision_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 137\u001b[0m\n\u001b[0;32m    134\u001b[0m y_pred_classes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(y_pred, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# Calcul des m√©triques d√©taill√©es\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m detailed_metrics \u001b[38;5;241m=\u001b[39m calculate_detailed_metrics(\n\u001b[0;32m    138\u001b[0m     y_test_encoded, y_pred_classes, y_pred, \n\u001b[0;32m    139\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvector_name\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_type\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    140\u001b[0m )\n\u001b[0;32m    142\u001b[0m \u001b[38;5;66;03m# Stockage\u001b[39;00m\n\u001b[0;32m    143\u001b[0m models[vector_name] \u001b[38;5;241m=\u001b[39m model\n",
      "Cell \u001b[1;32mIn[14], line 62\u001b[0m, in \u001b[0;36mcalculate_detailed_metrics\u001b[1;34m(y_true, y_pred, y_pred_proba, model_name)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# M√©triques de base\u001b[39;00m\n\u001b[0;32m     61\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_true, y_pred)\n\u001b[1;32m---> 62\u001b[0m precision \u001b[38;5;241m=\u001b[39m precision_score(y_true, y_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     63\u001b[0m recall \u001b[38;5;241m=\u001b[39m recall_score(y_true, y_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     64\u001b[0m f1 \u001b[38;5;241m=\u001b[39m f1_score(y_true, y_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'precision_score' is not defined"
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "# 6. ENTRA√éNEMENT DES MOD√àLES\n",
    "# =============================================================\n",
    "print(\"\\nüöÄ ENTRA√éNEMENT DES MOD√àLES SP√âCIALIS√âS\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=7, min_lr=0.00001)\n",
    "\n",
    "# Stockage des r√©sultats\n",
    "models = {}\n",
    "histories = {}\n",
    "results = {}\n",
    "\n",
    "# Fonction pour visualiser la matrice de confusion\n",
    "def plot_confusion_matrix(y_true, y_pred, labels, model_name, accuracy):\n",
    "    \"\"\"\n",
    "    Visualise la matrice de confusion avec des annotations et statistiques\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=labels, yticklabels=labels,\n",
    "                cbar_kws={'label': 'Nombre de pr√©dictions'})\n",
    "    \n",
    "    plt.title(f'Matrice de Confusion - {model_name}\\nPr√©cision: {accuracy:.4f}', \n",
    "              fontsize=16, fontweight='bold')\n",
    "    plt.xlabel('Pr√©dictions', fontsize=12)\n",
    "    plt.ylabel('Vraies √©tiquettes', fontsize=12)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Affichage des statistiques d√©taill√©es\n",
    "    print(f\"\\nüìä Statistiques d√©taill√©es pour {model_name}:\")\n",
    "    print(\"-\" * 40)\n",
    "    for i, label in enumerate(labels):\n",
    "        tp = cm[i, i]  # True Positives\n",
    "        fp = cm[:, i].sum() - tp  # False Positives\n",
    "        fn = cm[i, :].sum() - tp  # False Negatives\n",
    "        \n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        print(f\"  {label}:\")\n",
    "        print(f\"    Pr√©cision: {precision:.4f}\")\n",
    "        print(f\"    Rappel: {recall:.4f}\")\n",
    "        print(f\"    F1-score: {f1:.4f}\")\n",
    "        print(f\"    Vrais positifs: {tp}\")\n",
    "\n",
    "# Fonction pour calculer et afficher toutes les m√©triques\n",
    "def calculate_detailed_metrics(y_true, y_pred, y_pred_proba, model_name):\n",
    "    \"\"\"\n",
    "    Calcule et affiche toutes les m√©triques d√©taill√©es\n",
    "    \"\"\"\n",
    "    # M√©triques de base\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    # AUC Score (pour classification binaire ou multi-classe)\n",
    "    if len(np.unique(y_true)) == 2:\n",
    "        auc = roc_auc_score(y_true, y_pred_proba[:, 1])\n",
    "    else:\n",
    "        auc = roc_auc_score(y_true, y_pred_proba, multi_class='ovr', average='weighted')\n",
    "    \n",
    "    # Matthews Correlation Coefficient\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    \n",
    "    # Affichage du rapport de classification\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Classification Report - {model_name}\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    \n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Metrics - {model_name}\")\n",
    "    print(f\"Model                {model_name}\")\n",
    "    print(f\"AUC Score                   {auc:.6f}\")\n",
    "    print(f\"MCC                         {mcc:.6f}\")\n",
    "    print(f\"Precision Score             {precision:.6f}\")\n",
    "    print(f\"Recall Score               {recall:.6f}\")\n",
    "    print(f\"f1-score                   {f1:.6f}\")\n",
    "    print(f\"Accuracy Score             {accuracy:.6f}\")\n",
    "    \n",
    "    # Cr√©ation d'un DataFrame pour les m√©triques\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Metric': ['AUC Score', 'MCC', 'Precision Score', 'Recall Score', 'f1-score', 'Accuracy Score'],\n",
    "        'Value': [auc, mcc, precision, recall, f1, accuracy]\n",
    "    })\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'auc_score': auc,\n",
    "        'mcc': mcc,\n",
    "        'metrics_df': metrics_df\n",
    "    }\n",
    "\n",
    "# Noms des classes pour l'affichage\n",
    "class_names = ['Classe_0', 'Classe_1', 'Classe_2']  # Remplacez par vos vraies classes\n",
    "\n",
    "for vector_name, (model_type, model_creator) in model_assignment.items():\n",
    "    print(f\"\\nüéØ Entra√Ænement: {vector_name.upper()} avec mod√®le {model_type.upper()}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    X_train_lsa, X_test_lsa = lsa_vectors[vector_name]\n",
    "    \n",
    "    # Cr√©ation du mod√®le sp√©cialis√©\n",
    "    model = model_creator(X_train_lsa.shape[1], num_classes)\n",
    "    \n",
    "    print(f\"üìä Architecture: {model.name}\")\n",
    "    print(f\"üìè Input shape: {X_train_lsa.shape}\")\n",
    "    print(f\"üî¢ Param√®tres: {model.count_params():,}\")\n",
    "    \n",
    "    # Entra√Ænement\n",
    "    history = model.fit(\n",
    "        X_train_lsa, y_train_categorical,\n",
    "        validation_data=(X_test_lsa, y_test_categorical),\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        callbacks=[early_stopping, reduce_lr],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Pr√©dictions\n",
    "    y_pred = model.predict(X_test_lsa, verbose=0)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    \n",
    "    # Calcul des m√©triques d√©taill√©es\n",
    "    detailed_metrics = calculate_detailed_metrics(\n",
    "        y_test_encoded, y_pred_classes, y_pred, \n",
    "        f\"{vector_name.upper()} {model_type.upper()}\"\n",
    "    )\n",
    "    \n",
    "    # Stockage\n",
    "    models[vector_name] = model\n",
    "    histories[vector_name] = history\n",
    "    results[vector_name] = {\n",
    "        'accuracy': detailed_metrics['accuracy'],\n",
    "        'precision': detailed_metrics['precision'],\n",
    "        'recall': detailed_metrics['recall'],\n",
    "        'f1_score': detailed_metrics['f1_score'],\n",
    "        'auc_score': detailed_metrics['auc_score'],\n",
    "        'mcc': detailed_metrics['mcc'],\n",
    "        'model_type': model_type,\n",
    "        'y_pred': y_pred_classes,\n",
    "        'y_pred_proba': y_pred,\n",
    "        'epochs_trained': len(history.history['loss']),\n",
    "        'metrics_df': detailed_metrics['metrics_df']\n",
    "    }\n",
    "    \n",
    "    print(f\"‚úÖ Pr√©cision finale: {detailed_metrics['accuracy']:.4f}\")\n",
    "    print(f\"üìà √âpoques entra√Æn√©es: {results[vector_name]['epochs_trained']}\")\n",
    "    \n",
    "    # VISUALISATION DE LA MATRICE DE CONFUSION\n",
    "    print(f\"\\nüé® Visualisation de la matrice de confusion pour {vector_name.upper()}\")\n",
    "    plot_confusion_matrix(y_test_encoded, y_pred_classes, class_names, \n",
    "                         f\"{vector_name.upper()} + {model_type.upper()}\", \n",
    "                         detailed_metrics['accuracy'])\n",
    "\n",
    "# =============================================================\n",
    "# 7. VISUALISATION COMPARATIVE DES MATRICES DE CONFUSION\n",
    "# =============================================================\n",
    "print(\"\\nüé® VISUALISATION COMPARATIVE DES MATRICES DE CONFUSION\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# Cr√©er une figure avec sous-graphiques pour comparer toutes les matrices\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (vector_name, result) in enumerate(results.items()):\n",
    "    if idx < len(axes):\n",
    "        cm = confusion_matrix(y_test_encoded, result['y_pred'])\n",
    "        \n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                   xticklabels=class_names, yticklabels=class_names,\n",
    "                   ax=axes[idx], cbar=True)\n",
    "        \n",
    "        axes[idx].set_title(f'{vector_name.upper()} + {result[\"model_type\"].upper()}\\n'\n",
    "                           f'Pr√©cision: {result[\"accuracy\"]:.4f}', \n",
    "                           fontsize=12, fontweight='bold')\n",
    "        axes[idx].set_xlabel('Pr√©dictions')\n",
    "        axes[idx].set_ylabel('Vraies √©tiquettes')\n",
    "\n",
    "# Masquer les axes non utilis√©s\n",
    "for idx in range(len(results), len(axes)):\n",
    "    axes[idx].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Comparaison des Matrices de Confusion - Mod√®les Deep Learning', \n",
    "             fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.show()\n",
    "\n",
    "# =============================================================\n",
    "# 8. TABLEAU R√âCAPITULATIF DES PERFORMANCES D√âTAILL√âES\n",
    "# =============================================================\n",
    "print(\"\\nüìã TABLEAU R√âCAPITULATIF DES PERFORMANCES D√âTAILL√âES\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# Cr√©er un DataFrame pour un affichage propre avec toutes les m√©triques\n",
    "performance_data = []\n",
    "for vector_name, result in results.items():\n",
    "    performance_data.append({\n",
    "        'Type de vecteur': vector_name.upper(),\n",
    "        'Mod√®le': result['model_type'].upper(),\n",
    "        'Accuracy': f\"{result['accuracy']:.6f}\",\n",
    "        'Precision': f\"{result['precision']:.6f}\",\n",
    "        'Recall': f\"{result['recall']:.6f}\",\n",
    "        'F1-Score': f\"{result['f1_score']:.6f}\",\n",
    "        'AUC Score': f\"{result['auc_score']:.6f}\",\n",
    "        'MCC': f\"{result['mcc']:.6f}\",\n",
    "        '√âpoques': result['epochs_trained']\n",
    "    })\n",
    "\n",
    "df_performance = pd.DataFrame(performance_data)\n",
    "print(df_performance.to_string(index=False))\n",
    "\n",
    "# Identification du meilleur mod√®le selon diff√©rentes m√©triques\n",
    "print(f\"\\nüèÜ CLASSEMENT DES MOD√àLES:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Meilleur selon l'accuracy\n",
    "best_accuracy = max(results.items(), key=lambda x: x[1]['accuracy'])\n",
    "print(f\"üéØ Meilleur Accuracy: {best_accuracy[0].upper()} + {best_accuracy[1]['model_type'].upper()}\")\n",
    "print(f\"   Score: {best_accuracy[1]['accuracy']:.6f}\")\n",
    "\n",
    "# Meilleur selon F1-score\n",
    "best_f1 = max(results.items(), key=lambda x: x[1]['f1_score'])\n",
    "print(f\"üéØ Meilleur F1-Score: {best_f1[0].upper()} + {best_f1[1]['model_type'].upper()}\")\n",
    "print(f\"   Score: {best_f1[1]['f1_score']:.6f}\")\n",
    "\n",
    "# Meilleur selon AUC\n",
    "best_auc = max(results.items(), key=lambda x: x[1]['auc_score'])\n",
    "print(f\"üéØ Meilleur AUC Score: {best_auc[0].upper()} + {best_auc[1]['model_type'].upper()}\")\n",
    "print(f\"   Score: {best_auc[1]['auc_score']:.6f}\")\n",
    "\n",
    "# =============================================================\n",
    "# 9. ANALYSE DES ERREURS DE CLASSIFICATION\n",
    "# =============================================================\n",
    "print(\"\\nüîç ANALYSE DES ERREURS DE CLASSIFICATION\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "def analyze_classification_errors(y_true, y_pred, class_names, model_name):\n",
    "    \"\"\"\n",
    "    Analyse d√©taill√©e des erreurs de classification\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    print(f\"\\nüìä Analyse des erreurs pour {model_name}:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Erreurs les plus fr√©quentes\n",
    "    errors = []\n",
    "    for i in range(len(class_names)):\n",
    "        for j in range(len(class_names)):\n",
    "            if i != j and cm[i, j] > 0:\n",
    "                errors.append({\n",
    "                    'Vraie classe': class_names[i],\n",
    "                    'Pr√©dite comme': class_names[j],\n",
    "                    'Nombre d\\'erreurs': cm[i, j],\n",
    "                    'Pourcentage': (cm[i, j] / cm[i, :].sum()) * 100\n",
    "                })\n",
    "    \n",
    "    # Trier par nombre d'erreurs\n",
    "    errors.sort(key=lambda x: x['Nombre d\\'erreurs'], reverse=True)\n",
    "    \n",
    "    print(\"üî• Top 3 des erreurs les plus fr√©quentes:\")\n",
    "    for i, error in enumerate(errors[:3]):\n",
    "        print(f\"  {i+1}. {error['Vraie classe']} ‚Üí {error['Pr√©dite comme']}: \"\n",
    "              f\"{error['Nombre d\\'erreurs']} erreurs ({error['Pourcentage']:.1f}%)\")\n",
    "\n",
    "# Analyser les erreurs pour le meilleur mod√®le (selon accuracy)\n",
    "best_vector_name = best_accuracy[0]\n",
    "best_result = best_accuracy[1]\n",
    "analyze_classification_errors(y_test_encoded, best_result['y_pred'], \n",
    "                             class_names, f\"{best_vector_name.upper()} + {best_result['model_type'].upper()}\")\n",
    "\n",
    "# =============================================================\n",
    "# 10. SAUVEGARDE DES R√âSULTATS\n",
    "# =============================================================\n",
    "print(\"\\nüíæ SAUVEGARDE DES R√âSULTATS\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Sauvegarder les m√©triques dans un fichier CSV\n",
    "all_metrics = []\n",
    "for vector_name, result in results.items():\n",
    "    metrics_row = {\n",
    "        'Model': f\"{vector_name.upper()} {result['model_type'].upper()}\",\n",
    "        'Vector_Type': vector_name.upper(),\n",
    "        'Model_Type': result['model_type'].upper(),\n",
    "        'Accuracy': result['accuracy'],\n",
    "        'Precision': result['precision'],\n",
    "        'Recall': result['recall'],\n",
    "        'F1_Score': result['f1_score'],\n",
    "        'AUC_Score': result['auc_score'],\n",
    "        'MCC': result['mcc'],\n",
    "        'Epochs_Trained': result['epochs_trained']\n",
    "    }\n",
    "    all_metrics.append(metrics_row)\n",
    "\n",
    "metrics_df = pd.DataFrame(all_metrics)\n",
    "metrics_df.to_csv('model_metrics_comparison.csv', index=False)\n",
    "print(\"‚úÖ M√©triques sauvegard√©es dans 'model_metrics_comparison.csv'\")\n",
    "\n",
    "print(f\"\\nüéâ ENTRA√éNEMENT TERMIN√â!\")\n",
    "print(f\"üìä {len(results)} mod√®les entra√Æn√©s avec succ√®s\")\n",
    "print(f\"üèÜ Meilleur mod√®le global: {best_accuracy[0].upper()} + {best_accuracy[1]['model_type'].upper()}\")\n",
    "print(f\"üéØ Score final: {best_accuracy[1]['accuracy']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8320cb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7db8a67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Dans votre code, vous pouvez calculer train_accuracy comme ceci :\\ntrain_pred = model.predict(X_train_lsa, verbose=0)\\ntrain_pred_classes = np.argmax(train_pred, axis=1)\\ntrain_accuracy = accuracy_score(y_train_encoded, train_pred_classes)\\n\\n# Puis l'utiliser :\\nreport = display_detailed_classification_report_extended(\\n    y_test_encoded, \\n    y_pred_classes, \\n    y_pred,\\n    model_name,\\n    class_names,\\n    train_accuracy=train_accuracy,\\n    cv_score=None  # ou votre score de validation crois√©e\\n)\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================\n",
    "# 6. ENTRA√éNEMENT DES MOD√àLES AVEC LEARNING CURVES\n",
    "# =============================================================\n",
    "print(\"\\nüöÄ ENTRA√éNEMENT DES MOD√àLES SP√âCIALIS√âS\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=7, min_lr=0.00001)\n",
    "\n",
    "# Stockage des r√©sultats\n",
    "models = {}\n",
    "histories = {}\n",
    "results = {}\n",
    "\n",
    "# Fonction pour visualiser la matrice de confusion\n",
    "def plot_confusion_matrix(y_true, y_pred, labels, model_name, accuracy):\n",
    "    \"\"\"\n",
    "    Visualise la matrice de confusion avec des annotations et statistiques\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=labels, yticklabels=labels,\n",
    "                cbar_kws={'label': 'Nombre de pr√©dictions'})\n",
    "    \n",
    "    plt.title(f'Matrice de Confusion - {model_name}\\nPr√©cision: {accuracy:.4f}', \n",
    "              fontsize=16, fontweight='bold')\n",
    "    plt.xlabel('Pr√©dictions', fontsize=12)\n",
    "    plt.ylabel('Vraies √©tiquettes', fontsize=12)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Affichage des statistiques d√©taill√©es\n",
    "    print(f\"\\nüìä Statistiques d√©taill√©es pour {model_name}:\")\n",
    "    print(\"-\" * 40)\n",
    "    for i, label in enumerate(labels):\n",
    "        tp = cm[i, i]  # True Positives\n",
    "        fp = cm[:, i].sum() - tp  # False Positives\n",
    "        fn = cm[i, :].sum() - tp  # False Negatives\n",
    "        \n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        print(f\"  {label}:\")\n",
    "        print(f\"    Pr√©cision: {precision:.4f}\")\n",
    "        print(f\"    Rappel: {recall:.4f}\")\n",
    "        print(f\"    F1-score: {f1:.4f}\")\n",
    "        print(f\"    Vrais positifs: {tp}\")\n",
    "\n",
    "# NOUVELLE FONCTION : Affichage du rapport de classification\n",
    "def display_classification_report(y_true, y_pred, class_names, model_name):\n",
    "    \"\"\"\n",
    "    Affiche le rapport de classification d√©taill√© avec mise en forme\n",
    "    \"\"\"\n",
    "    print(f\"\\nüìã RAPPORT DE CLASSIFICATION - {model_name}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # G√©n√©rer le rapport\n",
    "    report = classification_report(y_true, y_pred, \n",
    "                                 target_names=class_names, \n",
    "                                 output_dict=True, \n",
    "                                 zero_division=0)\n",
    "    \n",
    "    # Affichage format√© du rapport\n",
    "    print(f\"{'Classe':<15} {'Pr√©cision':<12} {'Rappel':<12} {'F1-Score':<12} {'Support':<8}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for class_name in class_names:\n",
    "        if class_name in report:\n",
    "            metrics = report[class_name]\n",
    "            print(f\"{class_name:<15} {metrics['precision']:<12.4f} {metrics['recall']:<12.4f} \"\n",
    "                  f\"{metrics['f1-score']:<12.4f} {int(metrics['support']):<8}\")\n",
    "    \n",
    "    # Moyennes\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"{'Macro avg':<15} {report['macro avg']['precision']:<12.4f} \"\n",
    "          f\"{report['macro avg']['recall']:<12.4f} {report['macro avg']['f1-score']:<12.4f} \"\n",
    "          f\"{int(report['macro avg']['support']):<8}\")\n",
    "    \n",
    "    print(f\"{'Weighted avg':<15} {report['weighted avg']['precision']:<12.4f} \"\n",
    "          f\"{report['weighted avg']['recall']:<12.4f} {report['weighted avg']['f1-score']:<12.4f} \"\n",
    "          f\"{int(report['weighted avg']['support']):<8}\")\n",
    "    \n",
    "    print(f\"{'Accuracy':<15} {report['accuracy']:<12.4f}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Analyse des performances par classe\n",
    "    print(f\"\\nüîç Analyse des performances par classe:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    best_class = max(class_names, key=lambda x: report[x]['f1-score'] if x in report else 0)\n",
    "    worst_class = min(class_names, key=lambda x: report[x]['f1-score'] if x in report else 1)\n",
    "    \n",
    "    print(f\"üèÜ Meilleure classe: {best_class} (F1-Score: {report[best_class]['f1-score']:.4f})\")\n",
    "    print(f\"‚ö†Ô∏è  Classe la plus difficile: {worst_class} (F1-Score: {report[worst_class]['f1-score']:.4f})\")\n",
    "    \n",
    "    # D√©tection des d√©s√©quilibres\n",
    "    supports = [report[class_name]['support'] for class_name in class_names if class_name in report]\n",
    "    if max(supports) / min(supports) > 2:\n",
    "        print(f\"‚öñÔ∏è  D√©s√©quilibre d√©tect√© dans les classes (ratio: {max(supports)/min(supports):.1f}:1)\")\n",
    "    \n",
    "    return report\n",
    "\n",
    "# NOUVELLE FONCTION : Visualisation des Learning Curves\n",
    "def plot_learning_curves(history, model_name):\n",
    "    \"\"\"\n",
    "    Visualise les learning curves pour loss et accuracy\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Extraction des m√©triques\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    train_acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    \n",
    "    epochs = range(1, len(train_loss) + 1)\n",
    "    \n",
    "    # Graphique 1: Loss\n",
    "    ax1.plot(epochs, train_loss, 'b-', label='Loss d\\'entra√Ænement', linewidth=2)\n",
    "    ax1.plot(epochs, val_loss, 'r-', label='Loss de validation', linewidth=2)\n",
    "    ax1.set_title(f'Learning Curves - Loss\\n{model_name}', fontsize=14, fontweight='bold')\n",
    "    ax1.set_xlabel('√âpoques')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Graphique 2: Accuracy\n",
    "    ax2.plot(epochs, train_acc, 'b-', label='Accuracy d\\'entra√Ænement', linewidth=2)\n",
    "    ax2.plot(epochs, val_acc, 'r-', label='Accuracy de validation', linewidth=2)\n",
    "    ax2.set_title(f'Learning Curves - Accuracy\\n{model_name}', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlabel('√âpoques')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Ajout des valeurs finales dans le titre\n",
    "    final_train_acc = train_acc[-1]\n",
    "    final_val_acc = val_acc[-1]\n",
    "    \n",
    "    plt.suptitle(f'Accuracy finale - Train: {final_train_acc:.4f} | Validation: {final_val_acc:.4f}', \n",
    "                fontsize=12, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Analyse de l'overfitting/underfitting\n",
    "    print(f\"\\nüîç Analyse de l'apprentissage pour {model_name}:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Diff√©rence entre train et validation\n",
    "    acc_gap = final_train_acc - final_val_acc\n",
    "    loss_gap = val_loss[-1] - train_loss[-1]\n",
    "    \n",
    "    print(f\"üìä Accuracy finale:\")\n",
    "    print(f\"  - Entra√Ænement: {final_train_acc:.4f}\")\n",
    "    print(f\"  - Validation: {final_val_acc:.4f}\")\n",
    "    print(f\"  - √âcart: {acc_gap:.4f}\")\n",
    "    \n",
    "    # Diagnostic\n",
    "    if acc_gap > 0.1:\n",
    "        print(\"‚ö†Ô∏è  ALERTE: Possible overfitting d√©tect√© (√©cart > 0.1)\")\n",
    "    elif acc_gap < 0.05:\n",
    "        print(\"‚úÖ Bon √©quilibre entre entra√Ænement et validation\")\n",
    "    else:\n",
    "        print(\"üîÑ L√©ger overfitting, dans les limites acceptables\")\n",
    "    \n",
    "    # Tendance des derni√®res √©poques\n",
    "    last_5_val_acc = val_acc[-5:]\n",
    "    if len(last_5_val_acc) >= 5:\n",
    "        trend = np.polyfit(range(5), last_5_val_acc, 1)[0]\n",
    "        if trend > 0.001:\n",
    "            print(\"üìà Tendance: Am√©lioration continue\")\n",
    "        elif trend < -0.001:\n",
    "            print(\"üìâ Tendance: D√©gradation en fin d'entra√Ænement\")\n",
    "        else:\n",
    "            print(\"üìä Tendance: Stabilisation\")\n",
    "\n",
    "# Noms des classes pour l'affichage\n",
    "class_names = ['Classe_0', 'Classe_1', 'Classe_2']  # Remplacez par vos vraies classes\n",
    "\n",
    "for vector_name, (model_type, model_creator) in model_assignment.items():\n",
    "    print(f\"\\nüéØ Entra√Ænement: {vector_name.upper()} avec mod√®le {model_type.upper()}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    X_train_lsa, X_test_lsa = lsa_vectors[vector_name]\n",
    "    \n",
    "    # Cr√©ation du mod√®le sp√©cialis√©\n",
    "    model = model_creator(X_train_lsa.shape[1], num_classes)\n",
    "    \n",
    "    print(f\"üìä Architecture: {model.name}\")\n",
    "    print(f\"üìè Input shape: {X_train_lsa.shape}\")\n",
    "    print(f\"üî¢ Param√®tres: {model.count_params():,}\")\n",
    "    \n",
    "    # Entra√Ænement\n",
    "    history = model.fit(\n",
    "        X_train_lsa, y_train_categorical,\n",
    "        validation_data=(X_test_lsa, y_test_categorical),\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        callbacks=[early_stopping, reduce_lr],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Pr√©dictions\n",
    "    y_pred = model.predict(X_test_lsa, verbose=0)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    \n",
    "    # M√©triques\n",
    "    accuracy = accuracy_score(y_test_encoded, y_pred_classes)\n",
    "    \n",
    "    # Stockage\n",
    "    models[vector_name] = model\n",
    "    histories[vector_name] = history\n",
    "    results[vector_name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'model_type': model_type,\n",
    "        'y_pred': y_pred_classes,\n",
    "        'y_pred_proba': y_pred,\n",
    "        'epochs_trained': len(history.history['loss']),\n",
    "        'classification_report': None  # Sera rempli ci-dessous\n",
    "    }\n",
    "    \n",
    "    print(f\"‚úÖ Pr√©cision finale: {accuracy:.4f}\")\n",
    "    print(f\"üìà √âpoques entra√Æn√©es: {results[vector_name]['epochs_trained']}\")\n",
    "    \n",
    "    # NOUVEAU : Affichage du rapport de classification\n",
    "    report = display_classification_report(y_test_encoded, y_pred_classes, class_names, \n",
    "                                         f\"{vector_name.upper()} + {model_type.upper()}\")\n",
    "    results[vector_name]['classification_report'] = report\n",
    "    \n",
    "    # NOUVELLE VISUALISATION: Learning Curves\n",
    "    print(f\"\\nüìà Learning Curves pour {vector_name.upper()}\")\n",
    "    plot_learning_curves(history, f\"{vector_name.upper()} + {model_type.upper()}\")\n",
    "    \n",
    "    # VISUALISATION DE LA MATRICE DE CONFUSION\n",
    "    print(f\"\\nüé® Visualisation de la matrice de confusion pour {vector_name.upper()}\")\n",
    "    plot_confusion_matrix(y_test_encoded, y_pred_classes, class_names, \n",
    "                         f\"{vector_name.upper()} + {model_type.upper()}\", accuracy)\n",
    "\n",
    "# =============================================================\n",
    "# 7. VISUALISATION COMPARATIVE DES LEARNING CURVES\n",
    "# =============================================================\n",
    "print(\"\\nüìà VISUALISATION COMPARATIVE DES LEARNING CURVES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Cr√©er une figure comparative pour toutes les learning curves\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (vector_name, history) in enumerate(histories.items()):\n",
    "    if idx < len(axes):\n",
    "        # Extraction des donn√©es\n",
    "        train_acc = history.history['accuracy']\n",
    "        val_acc = history.history['val_accuracy']\n",
    "        epochs = range(1, len(train_acc) + 1)\n",
    "        \n",
    "        # Graphique\n",
    "        axes[idx].plot(epochs, train_acc, 'b-', label='Train', linewidth=2)\n",
    "        axes[idx].plot(epochs, val_acc, 'r-', label='Validation', linewidth=2)\n",
    "        axes[idx].set_title(f'{vector_name.upper()} + {results[vector_name][\"model_type\"].upper()}\\n'\n",
    "                           f'Val Acc: {val_acc[-1]:.4f}', \n",
    "                           fontsize=12, fontweight='bold')\n",
    "        axes[idx].set_xlabel('√âpoques')\n",
    "        axes[idx].set_ylabel('Accuracy')\n",
    "        axes[idx].legend()\n",
    "        axes[idx].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Limites y pour une meilleure comparaison\n",
    "        axes[idx].set_ylim([0.4, 1.0])\n",
    "\n",
    "# Masquer les axes non utilis√©s\n",
    "for idx in range(len(histories), len(axes)):\n",
    "    axes[idx].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Comparaison des Learning Curves - Accuracy Train vs Validation', \n",
    "             fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.show()\n",
    "\n",
    "# =============================================================\n",
    "# 8. ANALYSE COMPARATIVE DES PERFORMANCES D'APPRENTISSAGE\n",
    "# =============================================================\n",
    "print(\"\\nüîç ANALYSE COMPARATIVE DES PERFORMANCES D'APPRENTISSAGE\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# Cr√©er un tableau comparatif d√©taill√©\n",
    "learning_analysis = []\n",
    "for vector_name, history in histories.items():\n",
    "    train_acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    \n",
    "    final_train_acc = train_acc[-1]\n",
    "    final_val_acc = val_acc[-1]\n",
    "    best_val_acc = max(val_acc)\n",
    "    epochs_to_best = val_acc.index(best_val_acc) + 1\n",
    "    \n",
    "    learning_analysis.append({\n",
    "        'Mod√®le': f\"{vector_name.upper()} + {results[vector_name]['model_type'].upper()}\",\n",
    "        'Train Acc': f\"{final_train_acc:.4f}\",\n",
    "        'Val Acc': f\"{final_val_acc:.4f}\",\n",
    "        'Meilleure Val': f\"{best_val_acc:.4f}\",\n",
    "        '√âpoque meilleure': epochs_to_best,\n",
    "        '√âcart Train-Val': f\"{final_train_acc - final_val_acc:.4f}\",\n",
    "        'Overfitting': 'Oui' if (final_train_acc - final_val_acc) > 0.1 else 'Non'\n",
    "    })\n",
    "\n",
    "df_learning = pd.DataFrame(learning_analysis)\n",
    "print(df_learning.to_string(index=False))\n",
    "\n",
    "# =============================================================\n",
    "# 9. COMPARAISON DES RAPPORTS DE CLASSIFICATION\n",
    "# =============================================================\n",
    "print(\"\\nüìä COMPARAISON DES RAPPORTS DE CLASSIFICATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Cr√©er un tableau comparatif des m√©triques F1-Score par classe\n",
    "f1_comparison = []\n",
    "for vector_name, result in results.items():\n",
    "    report = result['classification_report']\n",
    "    model_name = f\"{vector_name.upper()} + {result['model_type'].upper()}\"\n",
    "    \n",
    "    row = {'Mod√®le': model_name}\n",
    "    for class_name in class_names:\n",
    "        if class_name in report:\n",
    "            row[f'{class_name}_F1'] = f\"{report[class_name]['f1-score']:.4f}\"\n",
    "    \n",
    "    row['Macro_F1'] = f\"{report['macro avg']['f1-score']:.4f}\"\n",
    "    row['Weighted_F1'] = f\"{report['weighted avg']['f1-score']:.4f}\"\n",
    "    row['Accuracy'] = f\"{report['accuracy']:.4f}\"\n",
    "    \n",
    "    f1_comparison.append(row)\n",
    "\n",
    "df_f1_comparison = pd.DataFrame(f1_comparison)\n",
    "print(\"\\nüéØ Comparaison des F1-Scores par classe:\")\n",
    "print(df_f1_comparison.to_string(index=False))\n",
    "\n",
    "# Identification des meilleures performances par classe\n",
    "print(\"\\nüèÜ MEILLEURES PERFORMANCES PAR CLASSE:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for class_name in class_names:\n",
    "    best_f1 = 0\n",
    "    best_model = \"\"\n",
    "    for vector_name, result in results.items():\n",
    "        report = result['classification_report']\n",
    "        if class_name in report:\n",
    "            f1_score = report[class_name]['f1-score']\n",
    "            if f1_score > best_f1:\n",
    "                best_f1 = f1_score\n",
    "                best_model = f\"{vector_name.upper()} + {result['model_type'].upper()}\"\n",
    "    \n",
    "    print(f\"  {class_name}: {best_model} (F1-Score: {best_f1:.4f})\")\n",
    "\n",
    "# =============================================================\n",
    "# 10. VISUALISATION COMPARATIVE DES MATRICES DE CONFUSION\n",
    "# =============================================================\n",
    "print(\"\\nüé® VISUALISATION COMPARATIVE DES MATRICES DE CONFUSION\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# Cr√©er une figure avec sous-graphiques pour comparer toutes les matrices\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (vector_name, result) in enumerate(results.items()):\n",
    "    if idx < len(axes):\n",
    "        cm = confusion_matrix(y_test_encoded, result['y_pred'])\n",
    "        \n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                   xticklabels=class_names, yticklabels=class_names,\n",
    "                   ax=axes[idx], cbar=True)\n",
    "        \n",
    "        axes[idx].set_title(f'{vector_name.upper()} + {result[\"model_type\"].upper()}\\n'\n",
    "                           f'Pr√©cision: {result[\"accuracy\"]:.4f}', \n",
    "                           fontsize=12, fontweight='bold')\n",
    "        axes[idx].set_xlabel('Pr√©dictions')\n",
    "        axes[idx].set_ylabel('Vraies √©tiquettes')\n",
    "\n",
    "# Masquer les axes non utilis√©s\n",
    "for idx in range(len(results), len(axes)):\n",
    "    axes[idx].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Comparaison des Matrices de Confusion - Mod√®les Deep Learning', \n",
    "             fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.show()\n",
    "\n",
    "# =============================================================\n",
    "# 11. TABLEAU R√âCAPITULATIF DES PERFORMANCES\n",
    "# =============================================================\n",
    "print(\"\\nüìã TABLEAU R√âCAPITULATIF DES PERFORMANCES\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# Cr√©er un DataFrame pour un affichage propre\n",
    "performance_data = []\n",
    "for vector_name, result in results.items():\n",
    "    report = result['classification_report']\n",
    "    performance_data.append({\n",
    "        'Type de vecteur': vector_name.upper(),\n",
    "        'Mod√®le': result['model_type'].upper(),\n",
    "        'Pr√©cision': f\"{result['accuracy']:.4f}\",\n",
    "        'F1-Score Macro': f\"{report['macro avg']['f1-score']:.4f}\",\n",
    "        'F1-Score Weighted': f\"{report['weighted avg']['f1-score']:.4f}\",\n",
    "        '√âpoques': result['epochs_trained']\n",
    "    })\n",
    "\n",
    "df_performance = pd.DataFrame(performance_data)\n",
    "print(df_performance.to_string(index=False))\n",
    "\n",
    "# Identification du meilleur mod√®le (bas√© sur F1-Score macro)\n",
    "best_model_f1 = max(results.items(), key=lambda x: x[1]['classification_report']['macro avg']['f1-score'])\n",
    "best_model_acc = max(results.items(), key=lambda x: x[1]['accuracy'])\n",
    "\n",
    "print(f\"\\nüèÜ MEILLEUR MOD√àLE (F1-Score Macro): {best_model_f1[0].upper()} + {best_model_f1[1]['model_type'].upper()}\")\n",
    "print(f\"üéØ F1-Score Macro: {best_model_f1[1]['classification_report']['macro avg']['f1-score']:.4f}\")\n",
    "print(f\"üìä Pr√©cision: {best_model_f1[1]['accuracy']:.4f}\")\n",
    "\n",
    "print(f\"\\nüéØ MEILLEUR MOD√àLE (Pr√©cision): {best_model_acc[0].upper()} + {best_model_acc[1]['model_type'].upper()}\")\n",
    "print(f\"üìä Pr√©cision: {best_model_acc[1]['accuracy']:.4f}\")\n",
    "print(f\"üéØ F1-Score Macro: {best_model_acc[1]['classification_report']['macro avg']['f1-score']:.4f}\")\n",
    "\n",
    "# =============================================================\n",
    "# 12. ANALYSE DES ERREURS DE CLASSIFICATION\n",
    "# =============================================================\n",
    "print(\"\\nüîç ANALYSE DES ERREURS DE CLASSIFICATION\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "def analyze_classification_errors(y_true, y_pred, class_names, model_name):\n",
    "    \"\"\"\n",
    "    Analyse d√©taill√©e des erreurs de classification\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    print(f\"\\nüìä Analyse des erreurs pour {model_name}:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Erreurs les plus fr√©quentes\n",
    "    errors = []\n",
    "    for i in range(len(class_names)):\n",
    "        for j in range(len(class_names)):\n",
    "            if i != j and cm[i, j] > 0:\n",
    "                errors.append({\n",
    "                    'Vraie classe': class_names[i],\n",
    "                    'Pr√©dite comme': class_names[j],\n",
    "                    'Nombre d\\'erreurs': cm[i, j],\n",
    "                    'Pourcentage': (cm[i, j] / cm[i, :].sum()) * 100\n",
    "                })\n",
    "    \n",
    "    # Trier par nombre d'erreurs\n",
    "    errors.sort(key=lambda x: x['Nombre d\\'erreurs'], reverse=True)\n",
    "    \n",
    "    print(\"üî• Top 3 des erreurs les plus fr√©quentes:\")\n",
    "    for i, error in enumerate(errors[:3]):\n",
    "        print(f\"  {i+1}. {error['Vraie classe']} ‚Üí {error['Pr√©dite comme']}: \"\n",
    "              f\"{error['Nombre d\\'erreurs']} erreurs ({error['Pourcentage']:.1f}%)\")\n",
    "\n",
    "# Analyser les erreurs pour le meilleur mod√®le\n",
    "best_vector_name = best_model_f1[0]\n",
    "best_result = best_model_f1[1]\n",
    "analyze_classification_errors(y_test_encoded, best_result['y_pred'], \n",
    "                             class_names, f\"{best_vector_name.upper()} + {best_result['model_type'].upper()}\")\n",
    "\n",
    "# =============================================================\n",
    "# 13. VISUALISATION DES M√âTRIQUES F1-SCORE PAR CLASSE\n",
    "# =============================================================\n",
    "print(\"\\nüìä VISUALISATION DES M√âTRIQUES F1-SCORE PAR CLASSE\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# Cr√©er un graphique en barres pour comparer les F1-Scores\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "# Donn√©es pour le graphique\n",
    "models_names = []\n",
    "f1_scores_by_class = {class_name: [] for class_name in class_names}\n",
    "\n",
    "for vector_name, result in results.items():\n",
    "    model_name = f\"{vector_name.upper()}\\n{result['model_type'].upper()}\"\n",
    "    models_names.append(model_name)\n",
    "    \n",
    "    report = result['classification_report']\n",
    "    for class_name in class_names:\n",
    "        if class_name in report:\n",
    "            f1_scores_by_class[class_name].append(report[class_name]['f1-score'])\n",
    "        else:\n",
    "            f1_scores_by_class[class_name].append(0)\n",
    "\n",
    "# Cr√©er le graphique en barres group√©es\n",
    "x = np.arange(len(models_names))\n",
    "width = 0.25\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    ax.bar(x + i * width, f1_scores_by_class[class_name], width, \n",
    "           label=class_name, alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Mod√®les')\n",
    "ax.set_ylabel('F1-Score')\n",
    "ax.set_title('Comparaison des F1-Scores par Classe et par Mod√®le')\n",
    "ax.set_xticks(x + width)\n",
    "ax.set_xticklabels(models_names, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim(0, 1.1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüéâ ANALYSE COMPL√àTE TERMIN√âE!\")\n",
    "print(\"=\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1583a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score, matthews_corrcoef, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "def display_detailed_classification_report(y_true, y_pred, y_pred_proba, model_name, class_names=None, train_accuracy=None, cv_score=None):\n",
    "    \"\"\"\n",
    "    Affiche un rapport de classification d√©taill√© dans le format demand√©\n",
    "    \n",
    "    Args:\n",
    "        y_true: Vraies √©tiquettes\n",
    "        y_pred: Pr√©dictions\n",
    "        y_pred_proba: Probabilit√©s pr√©dites\n",
    "        model_name: Nom du mod√®le\n",
    "        class_names: Noms des classes (optionnel)\n",
    "        train_accuracy: Pr√©cision sur l'ensemble d'entra√Ænement (optionnel)\n",
    "        cv_score: Score de validation crois√©e (optionnel)\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\nClassification Report - {model_name}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Rapport de classification standard\n",
    "    if class_names is None:\n",
    "        class_names = [str(i) for i in range(len(np.unique(y_true)))]\n",
    "    \n",
    "    # G√©n√©rer le rapport\n",
    "    report = classification_report(y_true, y_pred, \n",
    "                                 target_names=class_names,\n",
    "                                 output_dict=True,\n",
    "                                 zero_division=0)\n",
    "    \n",
    "    # Affichage format√© du rapport principal\n",
    "    print(f\"{'':>12} {'precision':>10} {'recall':>8} {'f1-score':>10} {'support':>8}\")\n",
    "    print()\n",
    "    \n",
    "    # Affichage par classe\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        if class_name in report:\n",
    "            metrics = report[class_name]\n",
    "            print(f\"{class_name:>12} {metrics['precision']:>10.2f} {metrics['recall']:>8.2f} \"\n",
    "                  f\"{metrics['f1-score']:>10.2f} {int(metrics['support']):>8}\")\n",
    "    \n",
    "    print()\n",
    "    # M√©triques globales\n",
    "    print(f\"{'accuracy':>12} {'':<10} {'':<8} {report['accuracy']:>10.2f} {int(report['macro avg']['support']):>8}\")\n",
    "    print(f\"{'macro avg':>12} {report['macro avg']['precision']:>10.2f} {report['macro avg']['recall']:>8.2f} \"\n",
    "          f\"{report['macro avg']['f1-score']:>10.2f} {int(report['macro avg']['support']):>8}\")\n",
    "    print(f\"{'weighted avg':>12} {report['weighted avg']['precision']:>10.2f} {report['weighted avg']['recall']:>8.2f} \"\n",
    "          f\"{report['weighted avg']['f1-score']:>10.2f} {int(report['weighted avg']['support']):>8}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    \n",
    "    # M√©triques suppl√©mentaires\n",
    "    print(f\"Metrics - {model_name}\")\n",
    "    print(f\"{'Model':<20} {model_name}\")\n",
    "    \n",
    "    # Calcul des m√©triques suppl√©mentaires\n",
    "    try:\n",
    "        # AUC Score\n",
    "        if len(np.unique(y_true)) == 2:\n",
    "            auc_score = roc_auc_score(y_true, y_pred_proba[:, 1])\n",
    "        else:\n",
    "            auc_score = roc_auc_score(y_true, y_pred_proba, multi_class='ovr')\n",
    "        print(f\"{'AUC Score':<20} {auc_score:>15.6f}\")\n",
    "    except:\n",
    "        print(f\"{'AUC Score':<20} {'N/A':>15}\")\n",
    "    \n",
    "    # Matthews Correlation Coefficient\n",
    "    try:\n",
    "        mcc = matthews_corrcoef(y_true, y_pred)\n",
    "        print(f\"{'MCC':<20} {mcc:>15.6f}\")\n",
    "    except:\n",
    "        print(f\"{'MCC':<20} {'N/A':>15}\")\n",
    "    \n",
    "    # Precision Score (macro)\n",
    "    precision_score = report['macro avg']['precision']\n",
    "    print(f\"{'Precision Score':<20} {precision_score:>15.6f}\")\n",
    "    \n",
    "    # Recall Score (macro)\n",
    "    recall_score = report['macro avg']['recall']\n",
    "    print(f\"{'Recall Score':<20} {recall_score:>15.6f}\")\n",
    "    \n",
    "    # F1-score (macro)\n",
    "    f1_score = report['macro avg']['f1-score']\n",
    "    print(f\"{'f1-score':<20} {f1_score:>15.6f}\")\n",
    "    \n",
    "    # Accuracy Score\n",
    "    accuracy = report['accuracy']\n",
    "    print(f\"{'Accuracy Score':<20} {accuracy:>15.6f}\")\n",
    "    \n",
    "    # Train Accuracy (si fourni)\n",
    "    if train_accuracy is not None:\n",
    "        print(f\"{'Train Accuracy':<20} {train_accuracy:>15.6f}\")\n",
    "    \n",
    "    # CV Score (si fourni)\n",
    "    if cv_score is not None:\n",
    "        print(f\"{'CV':<20} {cv_score:>15.6f}\")\n",
    "    \n",
    "    print(f\"{'dtype: object':<20}\")\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    \n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8cc98873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä ANALYSE COMPARATIVE DES MOD√àLES\n",
      "==========================================\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'glove'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m ax1 \u001b[38;5;241m=\u001b[39m axes[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     13\u001b[0m vector_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(model_assignment\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m---> 14\u001b[0m accuracies \u001b[38;5;241m=\u001b[39m [results[v][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m vector_names]\n\u001b[0;32m     15\u001b[0m model_types \u001b[38;5;241m=\u001b[39m [results[v][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m vector_names]\n\u001b[0;32m     17\u001b[0m colors \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mskyblue\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msemantic\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlightgreen\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontextual\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msalmon\u001b[39m\u001b[38;5;124m'\u001b[39m}\n",
      "\u001b[1;31mKeyError\u001b[0m: 'glove'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x1200 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =============================================================\n",
    "# 7. ANALYSE COMPARATIVE DES MOD√àLES\n",
    "# =============================================================\n",
    "\n",
    "print(\"\\nüìä ANALYSE COMPARATIVE DES MOD√àLES\")\n",
    "print(\"=\" * 42)\n",
    "\n",
    "# Visualisation des performances\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Comparaison des pr√©cisions\n",
    "ax1 = axes[0, 0]\n",
    "vector_names = list(model_assignment.keys())\n",
    "accuracies = [results[v]['accuracy'] for v in vector_names]\n",
    "model_types = [results[v]['model_type'] for v in vector_names]\n",
    "\n",
    "colors = {'sparse': 'skyblue', 'semantic': 'lightgreen', 'contextual': 'salmon'}\n",
    "bar_colors = [colors[mt] for mt in model_types]\n",
    "\n",
    "bars = ax1.bar(vector_names, accuracies, color=bar_colors)\n",
    "ax1.set_title('Pr√©cision par Vecteur et Mod√®le Sp√©cialis√©', fontweight='bold')\n",
    "ax1.set_xlabel('Type de Vecteur')\n",
    "ax1.set_ylabel('Pr√©cision')\n",
    "ax1.set_xticklabels(vector_names, rotation=45)\n",
    "\n",
    "# Ajout des valeurs et types de mod√®les\n",
    "for bar, acc, mt in zip(bars, accuracies, model_types):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005, \n",
    "             f'{acc:.3f}\\n({mt})', ha='center', va='bottom', fontsize=8, fontweight='bold')\n",
    "\n",
    "# 2. √âvolution des loss\n",
    "ax2 = axes[0, 1]\n",
    "for vector_name in vector_names:\n",
    "    model_type = results[vector_name]['model_type']\n",
    "    ax2.plot(histories[vector_name].history['val_loss'], \n",
    "             label=f'{vector_name} ({model_type})', linewidth=2)\n",
    "\n",
    "ax2.set_title('√âvolution de la Loss de Validation', fontweight='bold')\n",
    "ax2.set_xlabel('√âpoque')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Comparaison par type de mod√®le\n",
    "ax3 = axes[1, 0]\n",
    "model_performance = {}\n",
    "for vector_name, result in results.items():\n",
    "    model_type = result['model_type']\n",
    "    if model_type not in model_performance:\n",
    "        model_performance[model_type] = []\n",
    "    model_performance[model_type].append(result['accuracy'])\n",
    "\n",
    "avg_performance = {mt: np.mean(perfs) for mt, perfs in model_performance.items()}\n",
    "model_types_list = list(avg_performance.keys())\n",
    "avg_accuracies = list(avg_performance.values())\n",
    "\n",
    "bars = ax3.bar(model_types_list, avg_accuracies, \n",
    "               color=[colors[mt] for mt in model_types_list])\n",
    "ax3.set_title('Performance Moyenne par Type de Mod√®le', fontweight='bold')\n",
    "ax3.set_xlabel('Type de Mod√®le')\n",
    "ax3.set_ylabel('Pr√©cision Moyenne')\n",
    "\n",
    "for bar, acc in zip(bars, avg_accuracies):\n",
    "    ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005, \n",
    "             f'{acc:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 4. Variance expliqu√©e par LSA\n",
    "ax4 = axes[1, 1]\n",
    "variance_data = [(v, lsa_models[v].explained_variance_ratio_.sum()) \n",
    "                 for v in vector_names]\n",
    "variance_data.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "vectors_sorted, variances = zip(*variance_data)\n",
    "bars = ax4.bar(vectors_sorted, variances, color='orange', alpha=0.7)\n",
    "ax4.set_title('Variance Expliqu√©e par LSA', fontweight='bold')\n",
    "ax4.set_xlabel('Type de Vecteur')\n",
    "ax4.set_ylabel('Variance Expliqu√©e')\n",
    "ax4.set_xticklabels(vectors_sorted, rotation=45)\n",
    "\n",
    "for bar, var in zip(bars, variances):\n",
    "    ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "             f'{var:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07f0dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã ANALYSE D√âTAILL√âE DES R√âSULTATS\n",
      "==========================================\n",
      "üèÜ MEILLEUR MOD√àLE:\n",
      "   Type de vecteur: TFIDF\n",
      "   Mod√®le utilis√©: SPARSE\n",
      "   Pr√©cision: 0.7671\n",
      "   √âpoques: 32\n",
      "\n",
      "üìä PERFORMANCE PAR TYPE DE MOD√àLE:\n",
      "         SPARSE: 0.7671 ¬± 0.0000\n",
      "       SEMANTIC: 0.4553 ¬± 0.1169\n",
      "     CONTEXTUAL: 0.6958 ¬± 0.0273\n",
      "\n",
      "üìã RAPPORTS D√âTAILL√âS:\n",
      "==================================================\n",
      "\n",
      "üéØ TFIDF + SPARSE:\n",
      "----------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Classe_0     0.6808    0.7872    0.7302      1631\n",
      "    Classe_1     0.8016    0.7273    0.7626      1672\n",
      "    Classe_2     0.8388    0.7875    0.8123      1638\n",
      "\n",
      "    accuracy                         0.7671      4941\n",
      "   macro avg     0.7737    0.7674    0.7684      4941\n",
      "weighted avg     0.7740    0.7671    0.7684      4941\n",
      "\n",
      "\n",
      "üéØ GLOVE + SEMANTIC:\n",
      "----------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Classe_0     0.0000    0.0000    0.0000      1631\n",
      "    Classe_1     0.3384    1.0000    0.5057      1672\n",
      "    Classe_2     0.0000    0.0000    0.0000      1638\n",
      "\n",
      "    accuracy                         0.3384      4941\n",
      "   macro avg     0.1128    0.3333    0.1686      4941\n",
      "weighted avg     0.1145    0.3384    0.1711      4941\n",
      "\n",
      "\n",
      "üéØ W2V + SEMANTIC:\n",
      "----------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Classe_0     0.5484    0.5040    0.5252      1631\n",
      "    Classe_1     0.6153    0.5299    0.5694      1672\n",
      "    Classe_2     0.5589    0.6832    0.6148      1638\n",
      "\n",
      "    accuracy                         0.5722      4941\n",
      "   macro avg     0.5742    0.5723    0.5698      4941\n",
      "weighted avg     0.5745    0.5722    0.5699      4941\n",
      "\n",
      "\n",
      "üéØ BERT + CONTEXTUAL:\n",
      "----------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Classe_0     0.6519    0.7014    0.6757      1631\n",
      "    Classe_1     0.7704    0.7004    0.7337      1672\n",
      "    Classe_2     0.7551    0.7680    0.7615      1638\n",
      "\n",
      "    accuracy                         0.7231      4941\n",
      "   macro avg     0.7258    0.7233    0.7236      4941\n",
      "weighted avg     0.7262    0.7231    0.7238      4941\n",
      "\n",
      "\n",
      "üéØ BERT_2 + CONTEXTUAL:\n",
      "----------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Classe_0     0.4989    1.0000    0.6657      1631\n",
      "    Classe_1     1.0000    1.0000    1.0000      1672\n",
      "    Classe_2     0.0000    0.0000    0.0000      1638\n",
      "\n",
      "    accuracy                         0.6685      4941\n",
      "   macro avg     0.4996    0.6667    0.5552      4941\n",
      "weighted avg     0.5031    0.6685    0.5581      4941\n",
      "\n"
     ]
    }
   ],
   "source": [
    " #8. ANALYSE D√âTAILL√âE DES R√âSULTATS\n",
    "# =============================================================\n",
    "\n",
    "print(\"\\nüìã ANALYSE D√âTAILL√âE DES R√âSULTATS\")\n",
    "print(\"=\" * 42)\n",
    "\n",
    "# Trouver le meilleur mod√®le\n",
    "best_vector = max(results.keys(), key=lambda k: results[k]['accuracy'])\n",
    "best_result = results[best_vector]\n",
    "\n",
    "print(f\"üèÜ MEILLEUR MOD√àLE:\")\n",
    "print(f\"   Type de vecteur: {best_vector.upper()}\")\n",
    "print(f\"   Mod√®le utilis√©: {best_result['model_type'].upper()}\")\n",
    "print(f\"   Pr√©cision: {best_result['accuracy']:.4f}\")\n",
    "print(f\"   √âpoques: {best_result['epochs_trained']}\")\n",
    "\n",
    "# Rapport par type de mod√®le\n",
    "print(f\"\\nüìä PERFORMANCE PAR TYPE DE MOD√àLE:\")\n",
    "for model_type, performances in model_performance.items():\n",
    "    print(f\"   {model_type.upper():>12}: {np.mean(performances):.4f} ¬± {np.std(performances):.4f}\")\n",
    "\n",
    "# Rapports d√©taill√©s pour chaque vecteur\n",
    "print(f\"\\nüìã RAPPORTS D√âTAILL√âS:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for vector_name in vector_names:\n",
    "    result = results[vector_name]\n",
    "    print(f\"\\nüéØ {vector_name.upper()} + {result['model_type'].upper()}:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    if hasattr(label_encoder, 'classes_'):\n",
    "        target_names = label_encoder.classes_\n",
    "    else:\n",
    "        target_names = [f'Classe_{i}' for i in range(num_classes)]\n",
    "    \n",
    "    print(classification_report(y_test_encoded, result['y_pred'], \n",
    "                              target_names=target_names, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "923be726",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 9. MATRICE DE CONFUSION POUR LE MEILLEUR MOD√àLE\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# =============================================================\u001b[39;00m\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[1;32m----> 5\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(y_test_encoded, results[best_vector][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(label_encoder, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclasses_\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m      8\u001b[0m     labels \u001b[38;5;241m=\u001b[39m label_encoder\u001b[38;5;241m.\u001b[39mclasses_\n",
      "\u001b[1;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 9. MATRICE DE CONFUSION POUR LE MEILLEUR MOD√àLE\n",
    "# =============================================================\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "cm = confusion_matrix(y_test_encoded, results[best_vector]['y_pred'])\n",
    "\n",
    "if hasattr(label_encoder, 'classes_'):\n",
    "    labels = label_encoder.classes_\n",
    "else:\n",
    "    labels = [f'Classe_{i}' for i in range(num_classes)]\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=labels, yticklabels=labels)\n",
    "plt.title(f'Matrice de Confusion - {best_vector.upper()} + {best_result[\"model_type\"].upper()}\\n'\n",
    "          f'Pr√©cision: {best_result[\"accuracy\"]:.4f}', fontweight='bold')\n",
    "plt.xlabel('Pr√©dictions')\n",
    "plt.ylabel('Vraies √©tiquettes')\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4136c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üß† JUSTIFICATION TH√âORIQUE DES CHOIX DE MOD√àLES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "üîß MOD√àLE 1 - DNN CLASSIQUE (pour TF-IDF):\n",
    "   üí° POURQUOI ?\n",
    "   ‚Ä¢ TF-IDF produit des vecteurs CREUX et de HAUTE DIMENSION\n",
    "   ‚Ä¢ La sparsit√© n√©cessite un DROPOUT √âLEV√â pour √©viter l'overfitting  \n",
    "   ‚Ä¢ BatchNormalization stabilise l'entra√Ænement sur donn√©es creuses\n",
    "   ‚Ä¢ Architecture PROFONDE pour capturer les patterns n-grammes complexes\n",
    "   \n",
    "üîß MOD√àLE 2 - CNN-LSTM (pour GloVe, Word2Vec):\n",
    "   üí° POURQUOI ?\n",
    "   ‚Ä¢ GloVe/Word2Vec capturent des RELATIONS S√âMANTIQUES riches\n",
    "   ‚Ä¢ CNN extrait des FEATURES LOCALES (√©quivalent n-grammes s√©mantiques)\n",
    "   ‚Ä¢ LSTM capture les D√âPENDANCES S√âQUENTIELLES dans l'espace s√©mantique\n",
    "   ‚Ä¢ Combinaison optimale pour exploiter la RICHESSE S√âMANTIQUE\n",
    "   \n",
    "üîß MOD√àLE 3 - ATTENTION-BASED (pour BERT):\n",
    "   üí° POURQUOI ?\n",
    "   ‚Ä¢ BERT fournit des repr√©sentations CONTEXTUELLES de haute qualit√©\n",
    "   ‚Ä¢ M√©canisme d'ATTENTION pour identifier les features importantes\n",
    "   ‚Ä¢ RESIDUAL CONNECTIONS pr√©servent l'information contextuelle\n",
    "   ‚Ä¢ Architecture complexe adapt√©e √† la RICHESSE CONTEXTUELLE de BERT\n",
    "\n",
    "üìä R√âSULTATS ATTENDUS:\n",
    "   ‚Ä¢ BERT devrait obtenir les MEILLEURES performances (contextuel)\n",
    "   ‚Ä¢ GloVe/Word2Vec: bonnes performances (s√©mantique)  \n",
    "   ‚Ä¢ TF-IDF: performances correctes mais inf√©rieures (statistique)\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a57682",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüíæ Sauvegarde des mod√®les et r√©sultats...\")\n",
    "\n",
    "# Sauvegarde des mod√®les LSA et scalers\n",
    "for vector_name in vector_names:\n",
    "    joblib.dump(lsa_models[vector_name], f\"{base}/lsa_model_{vector_name}.pkl\")\n",
    "    joblib.dump(scalers[vector_name], f\"{base}/scaler_{vector_name}.pkl\")\n",
    "\n",
    "# Sauvegarde des mod√®les Deep Learning\n",
    "for vector_name, model in models.items():\n",
    "    model.save(f\"{base}/specialized_model_{vector_name}.h5\")\n",
    "\n",
    "# Sauvegarde des r√©sultats\n",
    "joblib.dump(results, f\"{base}/specialized_results.pkl\")\n",
    "joblib.dump(model_assignment, f\"{base}/model_assignment.pkl\")\n",
    "joblib.dump(label_encoder, f\"{base}/label_encoder.pkl\")\n",
    "\n",
    "print(\"‚úÖ Sauvegarde termin√©e!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "679989e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÜ OPTIMISATION DU MEILLEUR MOD√àLE: TFIDF + SPARSE\n",
      "============================================================\n",
      "\n",
      "üöÄ LANCEMENT DE L'OPTIMISATION DU MEILLEUR MOD√àLE\n",
      "============================================================\n",
      "üîç Mode: Recherche rapide\n",
      "\n",
      "üîç LANCEMENT DE L'OPTIMISATION\n",
      "----------------------------------------\n",
      "üìä Nombre de combinaisons √† tester: 128\n",
      "‚è±Ô∏è Temps estim√©: 256 minutes\n",
      "\n",
      "üöÄ D√âBUT DES TESTS\n",
      "==================================================\n",
      "\n",
      "üß™ Test 1/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 32, 'dropout_rate1': 0.3, 'dropout_rate2': 0.4, 'learning_rate': 0.001, 'neurons_layer1': 128, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7679\n",
      "üìà √âpoques: 55\n",
      "‚è±Ô∏è Temps: 73.4s\n",
      "üèÜ NOUVEAU RECORD! Pr√©cision: 0.7679\n",
      "‚ùå Erreur: The filename must end in `.weights.h5`. Received: filepath=best_model_weights_0.7679.h5\n",
      "\n",
      "üß™ Test 2/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 32, 'dropout_rate1': 0.3, 'dropout_rate2': 0.4, 'learning_rate': 0.001, 'neurons_layer1': 128, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7640\n",
      "üìà √âpoques: 40\n",
      "‚è±Ô∏è Temps: 56.0s\n",
      "\n",
      "üß™ Test 3/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 32, 'dropout_rate1': 0.3, 'dropout_rate2': 0.4, 'learning_rate': 0.001, 'neurons_layer1': 256, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7662\n",
      "üìà √âpoques: 30\n",
      "‚è±Ô∏è Temps: 37.0s\n",
      "\n",
      "üß™ Test 4/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 32, 'dropout_rate1': 0.3, 'dropout_rate2': 0.4, 'learning_rate': 0.001, 'neurons_layer1': 256, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7673\n",
      "üìà √âpoques: 30\n",
      "‚è±Ô∏è Temps: 37.7s\n",
      "\n",
      "üß™ Test 5/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 32, 'dropout_rate1': 0.3, 'dropout_rate2': 0.4, 'learning_rate': 0.002, 'neurons_layer1': 128, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7705\n",
      "üìà √âpoques: 40\n",
      "‚è±Ô∏è Temps: 43.6s\n",
      "üèÜ NOUVEAU RECORD! Pr√©cision: 0.7705\n",
      "‚ùå Erreur: The filename must end in `.weights.h5`. Received: filepath=best_model_weights_0.7705.h5\n",
      "\n",
      "üß™ Test 6/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 32, 'dropout_rate1': 0.3, 'dropout_rate2': 0.4, 'learning_rate': 0.002, 'neurons_layer1': 128, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7687\n",
      "üìà √âpoques: 68\n",
      "‚è±Ô∏è Temps: 77.0s\n",
      "\n",
      "üß™ Test 7/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 32, 'dropout_rate1': 0.3, 'dropout_rate2': 0.4, 'learning_rate': 0.002, 'neurons_layer1': 256, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7664\n",
      "üìà √âpoques: 44\n",
      "‚è±Ô∏è Temps: 51.4s\n",
      "\n",
      "üß™ Test 8/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 32, 'dropout_rate1': 0.3, 'dropout_rate2': 0.4, 'learning_rate': 0.002, 'neurons_layer1': 256, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7685\n",
      "üìà √âpoques: 32\n",
      "‚è±Ô∏è Temps: 69.4s\n",
      "\n",
      "üß™ Test 9/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 32, 'dropout_rate1': 0.3, 'dropout_rate2': 0.5, 'learning_rate': 0.001, 'neurons_layer1': 128, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7705\n",
      "üìà √âpoques: 46\n",
      "‚è±Ô∏è Temps: 87.5s\n",
      "\n",
      "üß™ Test 10/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 32, 'dropout_rate1': 0.3, 'dropout_rate2': 0.5, 'learning_rate': 0.001, 'neurons_layer1': 128, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7654\n",
      "üìà √âpoques: 52\n",
      "‚è±Ô∏è Temps: 114.4s\n",
      "\n",
      "üß™ Test 11/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 32, 'dropout_rate1': 0.3, 'dropout_rate2': 0.5, 'learning_rate': 0.001, 'neurons_layer1': 256, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7691\n",
      "üìà √âpoques: 49\n",
      "‚è±Ô∏è Temps: 109.6s\n",
      "\n",
      "üß™ Test 12/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 32, 'dropout_rate1': 0.3, 'dropout_rate2': 0.5, 'learning_rate': 0.001, 'neurons_layer1': 256, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7671\n",
      "üìà √âpoques: 30\n",
      "‚è±Ô∏è Temps: 85.5s\n",
      "\n",
      "üß™ Test 13/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 32, 'dropout_rate1': 0.3, 'dropout_rate2': 0.5, 'learning_rate': 0.002, 'neurons_layer1': 128, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7737\n",
      "üìà √âpoques: 57\n",
      "‚è±Ô∏è Temps: 131.7s\n",
      "üèÜ NOUVEAU RECORD! Pr√©cision: 0.7737\n",
      "‚ùå Erreur: The filename must end in `.weights.h5`. Received: filepath=best_model_weights_0.7737.h5\n",
      "\n",
      "üß™ Test 14/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 32, 'dropout_rate1': 0.3, 'dropout_rate2': 0.5, 'learning_rate': 0.002, 'neurons_layer1': 128, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7703\n",
      "üìà √âpoques: 36\n",
      "‚è±Ô∏è Temps: 83.1s\n",
      "\n",
      "üß™ Test 15/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 32, 'dropout_rate1': 0.3, 'dropout_rate2': 0.5, 'learning_rate': 0.002, 'neurons_layer1': 256, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7671\n",
      "üìà √âpoques: 35\n",
      "‚è±Ô∏è Temps: 66.6s\n",
      "\n",
      "üß™ Test 16/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 32, 'dropout_rate1': 0.3, 'dropout_rate2': 0.5, 'learning_rate': 0.002, 'neurons_layer1': 256, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7743\n",
      "üìà √âpoques: 37\n",
      "‚è±Ô∏è Temps: 84.3s\n",
      "üèÜ NOUVEAU RECORD! Pr√©cision: 0.7743\n",
      "‚ùå Erreur: The filename must end in `.weights.h5`. Received: filepath=best_model_weights_0.7743.h5\n",
      "\n",
      "üß™ Test 17/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 32, 'dropout_rate1': 0.4, 'dropout_rate2': 0.4, 'learning_rate': 0.001, 'neurons_layer1': 128, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7715\n",
      "üìà √âpoques: 62\n",
      "‚è±Ô∏è Temps: 149.6s\n",
      "\n",
      "üß™ Test 18/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 32, 'dropout_rate1': 0.4, 'dropout_rate2': 0.4, 'learning_rate': 0.001, 'neurons_layer1': 128, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7703\n",
      "üìà √âpoques: 36\n",
      "‚è±Ô∏è Temps: 69.9s\n",
      "\n",
      "üß™ Test 19/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 32, 'dropout_rate1': 0.4, 'dropout_rate2': 0.4, 'learning_rate': 0.001, 'neurons_layer1': 256, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7731\n",
      "üìà √âpoques: 40\n",
      "‚è±Ô∏è Temps: 90.1s\n",
      "\n",
      "üß™ Test 20/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 32, 'dropout_rate1': 0.4, 'dropout_rate2': 0.4, 'learning_rate': 0.001, 'neurons_layer1': 256, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7656\n",
      "üìà √âpoques: 39\n",
      "‚è±Ô∏è Temps: 115.8s\n",
      "\n",
      "üß™ Test 21/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 32, 'dropout_rate1': 0.4, 'dropout_rate2': 0.4, 'learning_rate': 0.002, 'neurons_layer1': 128, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7691\n",
      "üìà √âpoques: 47\n",
      "‚è±Ô∏è Temps: 115.8s\n",
      "\n",
      "üß™ Test 22/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 32, 'dropout_rate1': 0.4, 'dropout_rate2': 0.4, 'learning_rate': 0.002, 'neurons_layer1': 128, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7717\n",
      "üìà √âpoques: 53\n",
      "‚è±Ô∏è Temps: 114.1s\n",
      "\n",
      "üß™ Test 23/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 32, 'dropout_rate1': 0.4, 'dropout_rate2': 0.4, 'learning_rate': 0.002, 'neurons_layer1': 256, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7677\n",
      "üìà √âpoques: 35\n",
      "‚è±Ô∏è Temps: 79.8s\n",
      "\n",
      "üß™ Test 24/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 32, 'dropout_rate1': 0.4, 'dropout_rate2': 0.4, 'learning_rate': 0.002, 'neurons_layer1': 256, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7721\n",
      "üìà √âpoques: 34\n",
      "‚è±Ô∏è Temps: 80.5s\n",
      "\n",
      "üß™ Test 25/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 32, 'dropout_rate1': 0.4, 'dropout_rate2': 0.5, 'learning_rate': 0.001, 'neurons_layer1': 128, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7658\n",
      "üìà √âpoques: 56\n",
      "‚è±Ô∏è Temps: 113.0s\n",
      "\n",
      "üß™ Test 26/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 32, 'dropout_rate1': 0.4, 'dropout_rate2': 0.5, 'learning_rate': 0.001, 'neurons_layer1': 128, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7705\n",
      "üìà √âpoques: 47\n",
      "‚è±Ô∏è Temps: 92.3s\n",
      "\n",
      "üß™ Test 27/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 32, 'dropout_rate1': 0.4, 'dropout_rate2': 0.5, 'learning_rate': 0.001, 'neurons_layer1': 256, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7727\n",
      "üìà √âpoques: 42\n",
      "‚è±Ô∏è Temps: 75.7s\n",
      "\n",
      "üß™ Test 28/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 32, 'dropout_rate1': 0.4, 'dropout_rate2': 0.5, 'learning_rate': 0.001, 'neurons_layer1': 256, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7735\n",
      "üìà √âpoques: 46\n",
      "‚è±Ô∏è Temps: 61.5s\n",
      "\n",
      "üß™ Test 29/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 32, 'dropout_rate1': 0.4, 'dropout_rate2': 0.5, 'learning_rate': 0.002, 'neurons_layer1': 128, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7729\n",
      "üìà √âpoques: 69\n",
      "‚è±Ô∏è Temps: 104.3s\n",
      "\n",
      "üß™ Test 30/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 32, 'dropout_rate1': 0.4, 'dropout_rate2': 0.5, 'learning_rate': 0.002, 'neurons_layer1': 128, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7683\n",
      "üìà √âpoques: 49\n",
      "‚è±Ô∏è Temps: 99.4s\n",
      "\n",
      "üß™ Test 31/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 32, 'dropout_rate1': 0.4, 'dropout_rate2': 0.5, 'learning_rate': 0.002, 'neurons_layer1': 256, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7721\n",
      "üìà √âpoques: 38\n",
      "‚è±Ô∏è Temps: 68.6s\n",
      "\n",
      "üß™ Test 32/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 32, 'dropout_rate1': 0.4, 'dropout_rate2': 0.5, 'learning_rate': 0.002, 'neurons_layer1': 256, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7652\n",
      "üìà √âpoques: 37\n",
      "‚è±Ô∏è Temps: 84.1s\n",
      "\n",
      "üß™ Test 33/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 64, 'dropout_rate1': 0.3, 'dropout_rate2': 0.4, 'learning_rate': 0.001, 'neurons_layer1': 128, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7739\n",
      "üìà √âpoques: 47\n",
      "‚è±Ô∏è Temps: 54.8s\n",
      "\n",
      "üß™ Test 34/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 64, 'dropout_rate1': 0.3, 'dropout_rate2': 0.4, 'learning_rate': 0.001, 'neurons_layer1': 128, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7707\n",
      "üìà √âpoques: 53\n",
      "‚è±Ô∏è Temps: 63.7s\n",
      "\n",
      "üß™ Test 35/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 64, 'dropout_rate1': 0.3, 'dropout_rate2': 0.4, 'learning_rate': 0.001, 'neurons_layer1': 256, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7798\n",
      "üìà √âpoques: 49\n",
      "‚è±Ô∏è Temps: 63.5s\n",
      "üèÜ NOUVEAU RECORD! Pr√©cision: 0.7798\n",
      "‚ùå Erreur: The filename must end in `.weights.h5`. Received: filepath=best_model_weights_0.7798.h5\n",
      "\n",
      "üß™ Test 36/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 64, 'dropout_rate1': 0.3, 'dropout_rate2': 0.4, 'learning_rate': 0.001, 'neurons_layer1': 256, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7737\n",
      "üìà √âpoques: 42\n",
      "‚è±Ô∏è Temps: 57.4s\n",
      "\n",
      "üß™ Test 37/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 64, 'dropout_rate1': 0.3, 'dropout_rate2': 0.4, 'learning_rate': 0.002, 'neurons_layer1': 128, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7727\n",
      "üìà √âpoques: 67\n",
      "‚è±Ô∏è Temps: 77.8s\n",
      "\n",
      "üß™ Test 38/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 64, 'dropout_rate1': 0.3, 'dropout_rate2': 0.4, 'learning_rate': 0.002, 'neurons_layer1': 128, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7741\n",
      "üìà √âpoques: 45\n",
      "‚è±Ô∏è Temps: 55.7s\n",
      "\n",
      "üß™ Test 39/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 64, 'dropout_rate1': 0.3, 'dropout_rate2': 0.4, 'learning_rate': 0.002, 'neurons_layer1': 256, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7681\n",
      "üìà √âpoques: 36\n",
      "‚è±Ô∏è Temps: 48.8s\n",
      "\n",
      "üß™ Test 40/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 64, 'dropout_rate1': 0.3, 'dropout_rate2': 0.4, 'learning_rate': 0.002, 'neurons_layer1': 256, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7721\n",
      "üìà √âpoques: 37\n",
      "‚è±Ô∏è Temps: 56.8s\n",
      "\n",
      "üß™ Test 41/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 64, 'dropout_rate1': 0.3, 'dropout_rate2': 0.5, 'learning_rate': 0.001, 'neurons_layer1': 128, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7717\n",
      "üìà √âpoques: 62\n",
      "‚è±Ô∏è Temps: 73.3s\n",
      "\n",
      "üß™ Test 42/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 64, 'dropout_rate1': 0.3, 'dropout_rate2': 0.5, 'learning_rate': 0.001, 'neurons_layer1': 128, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7668\n",
      "üìà √âpoques: 52\n",
      "‚è±Ô∏è Temps: 35.6s\n",
      "\n",
      "üß™ Test 43/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 64, 'dropout_rate1': 0.3, 'dropout_rate2': 0.5, 'learning_rate': 0.001, 'neurons_layer1': 256, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7719\n",
      "üìà √âpoques: 38\n",
      "‚è±Ô∏è Temps: 35.5s\n",
      "\n",
      "üß™ Test 44/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 64, 'dropout_rate1': 0.3, 'dropout_rate2': 0.5, 'learning_rate': 0.001, 'neurons_layer1': 256, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7735\n",
      "üìà √âpoques: 45\n",
      "‚è±Ô∏è Temps: 54.8s\n",
      "\n",
      "üß™ Test 45/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 64, 'dropout_rate1': 0.3, 'dropout_rate2': 0.5, 'learning_rate': 0.002, 'neurons_layer1': 128, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7719\n",
      "üìà √âpoques: 39\n",
      "‚è±Ô∏è Temps: 33.2s\n",
      "\n",
      "üß™ Test 46/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 64, 'dropout_rate1': 0.3, 'dropout_rate2': 0.5, 'learning_rate': 0.002, 'neurons_layer1': 128, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7693\n",
      "üìà √âpoques: 51\n",
      "‚è±Ô∏è Temps: 65.1s\n",
      "\n",
      "üß™ Test 47/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 64, 'dropout_rate1': 0.3, 'dropout_rate2': 0.5, 'learning_rate': 0.002, 'neurons_layer1': 256, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7721\n",
      "üìà √âpoques: 45\n",
      "‚è±Ô∏è Temps: 60.6s\n",
      "\n",
      "üß™ Test 48/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 64, 'dropout_rate1': 0.3, 'dropout_rate2': 0.5, 'learning_rate': 0.002, 'neurons_layer1': 256, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7685\n",
      "üìà √âpoques: 45\n",
      "‚è±Ô∏è Temps: 59.5s\n",
      "\n",
      "üß™ Test 49/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 64, 'dropout_rate1': 0.4, 'dropout_rate2': 0.4, 'learning_rate': 0.001, 'neurons_layer1': 128, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7713\n",
      "üìà √âpoques: 56\n",
      "‚è±Ô∏è Temps: 65.9s\n",
      "\n",
      "üß™ Test 50/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 64, 'dropout_rate1': 0.4, 'dropout_rate2': 0.4, 'learning_rate': 0.001, 'neurons_layer1': 128, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7697\n",
      "üìà √âpoques: 62\n",
      "‚è±Ô∏è Temps: 60.9s\n",
      "\n",
      "üß™ Test 51/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 64, 'dropout_rate1': 0.4, 'dropout_rate2': 0.4, 'learning_rate': 0.001, 'neurons_layer1': 256, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7709\n",
      "üìà √âpoques: 52\n",
      "‚è±Ô∏è Temps: 76.8s\n",
      "\n",
      "üß™ Test 52/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 64, 'dropout_rate1': 0.4, 'dropout_rate2': 0.4, 'learning_rate': 0.001, 'neurons_layer1': 256, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7713\n",
      "üìà √âpoques: 57\n",
      "‚è±Ô∏è Temps: 63.1s\n",
      "\n",
      "üß™ Test 53/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 64, 'dropout_rate1': 0.4, 'dropout_rate2': 0.4, 'learning_rate': 0.002, 'neurons_layer1': 128, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7703\n",
      "üìà √âpoques: 65\n",
      "‚è±Ô∏è Temps: 44.5s\n",
      "\n",
      "üß™ Test 54/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 64, 'dropout_rate1': 0.4, 'dropout_rate2': 0.4, 'learning_rate': 0.002, 'neurons_layer1': 128, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7679\n",
      "üìà √âpoques: 48\n",
      "‚è±Ô∏è Temps: 32.7s\n",
      "\n",
      "üß™ Test 55/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 64, 'dropout_rate1': 0.4, 'dropout_rate2': 0.4, 'learning_rate': 0.002, 'neurons_layer1': 256, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7756\n",
      "üìà √âpoques: 40\n",
      "‚è±Ô∏è Temps: 29.2s\n",
      "\n",
      "üß™ Test 56/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 64, 'dropout_rate1': 0.4, 'dropout_rate2': 0.4, 'learning_rate': 0.002, 'neurons_layer1': 256, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7709\n",
      "üìà √âpoques: 41\n",
      "‚è±Ô∏è Temps: 50.0s\n",
      "\n",
      "üß™ Test 57/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 64, 'dropout_rate1': 0.4, 'dropout_rate2': 0.5, 'learning_rate': 0.001, 'neurons_layer1': 128, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7703\n",
      "üìà √âpoques: 46\n",
      "‚è±Ô∏è Temps: 54.3s\n",
      "\n",
      "üß™ Test 58/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 64, 'dropout_rate1': 0.4, 'dropout_rate2': 0.5, 'learning_rate': 0.001, 'neurons_layer1': 128, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7697\n",
      "üìà √âpoques: 62\n",
      "‚è±Ô∏è Temps: 75.9s\n",
      "\n",
      "üß™ Test 59/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 64, 'dropout_rate1': 0.4, 'dropout_rate2': 0.5, 'learning_rate': 0.001, 'neurons_layer1': 256, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7691\n",
      "üìà √âpoques: 47\n",
      "‚è±Ô∏è Temps: 53.6s\n",
      "\n",
      "üß™ Test 60/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 64, 'dropout_rate1': 0.4, 'dropout_rate2': 0.5, 'learning_rate': 0.001, 'neurons_layer1': 256, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7733\n",
      "üìà √âpoques: 51\n",
      "‚è±Ô∏è Temps: 71.2s\n",
      "\n",
      "üß™ Test 61/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 64, 'dropout_rate1': 0.4, 'dropout_rate2': 0.5, 'learning_rate': 0.002, 'neurons_layer1': 128, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7745\n",
      "üìà √âpoques: 70\n",
      "‚è±Ô∏è Temps: 52.6s\n",
      "\n",
      "üß™ Test 62/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 64, 'dropout_rate1': 0.4, 'dropout_rate2': 0.5, 'learning_rate': 0.002, 'neurons_layer1': 128, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7711\n",
      "üìà √âpoques: 48\n",
      "‚è±Ô∏è Temps: 52.1s\n",
      "\n",
      "üß™ Test 63/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 64, 'dropout_rate1': 0.4, 'dropout_rate2': 0.5, 'learning_rate': 0.002, 'neurons_layer1': 256, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7776\n",
      "üìà √âpoques: 48\n",
      "‚è±Ô∏è Temps: 63.2s\n",
      "\n",
      "üß™ Test 64/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'relu', 'batch_size': 64, 'dropout_rate1': 0.4, 'dropout_rate2': 0.5, 'learning_rate': 0.002, 'neurons_layer1': 256, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7715\n",
      "üìà √âpoques: 49\n",
      "‚è±Ô∏è Temps: 70.5s\n",
      "\n",
      "üß™ Test 65/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 32, 'dropout_rate1': 0.3, 'dropout_rate2': 0.4, 'learning_rate': 0.001, 'neurons_layer1': 128, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7673\n",
      "üìà √âpoques: 49\n",
      "‚è±Ô∏è Temps: 89.2s\n",
      "\n",
      "üß™ Test 66/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 32, 'dropout_rate1': 0.3, 'dropout_rate2': 0.4, 'learning_rate': 0.001, 'neurons_layer1': 128, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7636\n",
      "üìà √âpoques: 38\n",
      "‚è±Ô∏è Temps: 81.1s\n",
      "\n",
      "üß™ Test 67/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 32, 'dropout_rate1': 0.3, 'dropout_rate2': 0.4, 'learning_rate': 0.001, 'neurons_layer1': 256, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7642\n",
      "üìà √âpoques: 47\n",
      "‚è±Ô∏è Temps: 107.6s\n",
      "\n",
      "üß™ Test 68/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 32, 'dropout_rate1': 0.3, 'dropout_rate2': 0.4, 'learning_rate': 0.001, 'neurons_layer1': 256, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7677\n",
      "üìà √âpoques: 39\n",
      "‚è±Ô∏è Temps: 91.5s\n",
      "\n",
      "üß™ Test 69/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 32, 'dropout_rate1': 0.3, 'dropout_rate2': 0.4, 'learning_rate': 0.002, 'neurons_layer1': 128, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7711\n",
      "üìà √âpoques: 56\n",
      "‚è±Ô∏è Temps: 106.4s\n",
      "\n",
      "üß™ Test 70/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 32, 'dropout_rate1': 0.3, 'dropout_rate2': 0.4, 'learning_rate': 0.002, 'neurons_layer1': 128, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7717\n",
      "üìà √âpoques: 50\n",
      "‚è±Ô∏è Temps: 105.9s\n",
      "\n",
      "üß™ Test 71/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 32, 'dropout_rate1': 0.3, 'dropout_rate2': 0.4, 'learning_rate': 0.002, 'neurons_layer1': 256, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7695\n",
      "üìà √âpoques: 59\n",
      "‚è±Ô∏è Temps: 129.5s\n",
      "\n",
      "üß™ Test 72/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 32, 'dropout_rate1': 0.3, 'dropout_rate2': 0.4, 'learning_rate': 0.002, 'neurons_layer1': 256, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7668\n",
      "üìà √âpoques: 33\n",
      "‚è±Ô∏è Temps: 80.8s\n",
      "\n",
      "üß™ Test 73/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 32, 'dropout_rate1': 0.3, 'dropout_rate2': 0.5, 'learning_rate': 0.001, 'neurons_layer1': 128, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7644\n",
      "üìà √âpoques: 41\n",
      "‚è±Ô∏è Temps: 71.2s\n",
      "\n",
      "üß™ Test 74/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 32, 'dropout_rate1': 0.3, 'dropout_rate2': 0.5, 'learning_rate': 0.001, 'neurons_layer1': 128, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7664\n",
      "üìà √âpoques: 45\n",
      "‚è±Ô∏è Temps: 51.6s\n",
      "\n",
      "üß™ Test 75/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 32, 'dropout_rate1': 0.3, 'dropout_rate2': 0.5, 'learning_rate': 0.001, 'neurons_layer1': 256, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7668\n",
      "üìà √âpoques: 65\n",
      "‚è±Ô∏è Temps: 76.0s\n",
      "\n",
      "üß™ Test 76/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 32, 'dropout_rate1': 0.3, 'dropout_rate2': 0.5, 'learning_rate': 0.001, 'neurons_layer1': 256, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7654\n",
      "üìà √âpoques: 76\n",
      "‚è±Ô∏è Temps: 93.4s\n",
      "\n",
      "üß™ Test 77/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 32, 'dropout_rate1': 0.3, 'dropout_rate2': 0.5, 'learning_rate': 0.002, 'neurons_layer1': 128, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7705\n",
      "üìà √âpoques: 48\n",
      "‚è±Ô∏è Temps: 64.3s\n",
      "\n",
      "üß™ Test 78/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 32, 'dropout_rate1': 0.3, 'dropout_rate2': 0.5, 'learning_rate': 0.002, 'neurons_layer1': 128, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7666\n",
      "üìà √âpoques: 40\n",
      "‚è±Ô∏è Temps: 56.7s\n",
      "\n",
      "üß™ Test 79/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 32, 'dropout_rate1': 0.3, 'dropout_rate2': 0.5, 'learning_rate': 0.002, 'neurons_layer1': 256, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7671\n",
      "üìà √âpoques: 41\n",
      "‚è±Ô∏è Temps: 60.9s\n",
      "\n",
      "üß™ Test 80/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 32, 'dropout_rate1': 0.3, 'dropout_rate2': 0.5, 'learning_rate': 0.002, 'neurons_layer1': 256, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7675\n",
      "üìà √âpoques: 35\n",
      "‚è±Ô∏è Temps: 54.6s\n",
      "\n",
      "üß™ Test 81/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 32, 'dropout_rate1': 0.4, 'dropout_rate2': 0.4, 'learning_rate': 0.001, 'neurons_layer1': 128, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7654\n",
      "üìà √âpoques: 42\n",
      "‚è±Ô∏è Temps: 57.0s\n",
      "\n",
      "üß™ Test 82/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 32, 'dropout_rate1': 0.4, 'dropout_rate2': 0.4, 'learning_rate': 0.001, 'neurons_layer1': 128, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7668\n",
      "üìà √âpoques: 63\n",
      "‚è±Ô∏è Temps: 94.5s\n",
      "\n",
      "üß™ Test 83/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 32, 'dropout_rate1': 0.4, 'dropout_rate2': 0.4, 'learning_rate': 0.001, 'neurons_layer1': 256, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7660\n",
      "üìà √âpoques: 46\n",
      "‚è±Ô∏è Temps: 70.5s\n",
      "\n",
      "üß™ Test 84/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 32, 'dropout_rate1': 0.4, 'dropout_rate2': 0.4, 'learning_rate': 0.001, 'neurons_layer1': 256, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7707\n",
      "üìà √âpoques: 51\n",
      "‚è±Ô∏è Temps: 82.9s\n",
      "\n",
      "üß™ Test 85/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 32, 'dropout_rate1': 0.4, 'dropout_rate2': 0.4, 'learning_rate': 0.002, 'neurons_layer1': 128, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7689\n",
      "üìà √âpoques: 44\n",
      "‚è±Ô∏è Temps: 60.4s\n",
      "\n",
      "üß™ Test 86/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 32, 'dropout_rate1': 0.4, 'dropout_rate2': 0.4, 'learning_rate': 0.002, 'neurons_layer1': 128, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7666\n",
      "üìà √âpoques: 46\n",
      "‚è±Ô∏è Temps: 65.3s\n",
      "\n",
      "üß™ Test 87/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 32, 'dropout_rate1': 0.4, 'dropout_rate2': 0.4, 'learning_rate': 0.002, 'neurons_layer1': 256, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7660\n",
      "üìà √âpoques: 49\n",
      "‚è±Ô∏è Temps: 106.0s\n",
      "\n",
      "üß™ Test 88/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 32, 'dropout_rate1': 0.4, 'dropout_rate2': 0.4, 'learning_rate': 0.002, 'neurons_layer1': 256, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7664\n",
      "üìà √âpoques: 40\n",
      "‚è±Ô∏è Temps: 81.6s\n",
      "\n",
      "üß™ Test 89/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 32, 'dropout_rate1': 0.4, 'dropout_rate2': 0.5, 'learning_rate': 0.001, 'neurons_layer1': 128, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7650\n",
      "üìà √âpoques: 52\n",
      "‚è±Ô∏è Temps: 77.2s\n",
      "\n",
      "üß™ Test 90/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 32, 'dropout_rate1': 0.4, 'dropout_rate2': 0.5, 'learning_rate': 0.001, 'neurons_layer1': 128, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7652\n",
      "üìà √âpoques: 56\n",
      "‚è±Ô∏è Temps: 85.5s\n",
      "\n",
      "üß™ Test 91/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 32, 'dropout_rate1': 0.4, 'dropout_rate2': 0.5, 'learning_rate': 0.001, 'neurons_layer1': 256, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7620\n",
      "üìà √âpoques: 44\n",
      "‚è±Ô∏è Temps: 66.4s\n",
      "\n",
      "üß™ Test 92/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 32, 'dropout_rate1': 0.4, 'dropout_rate2': 0.5, 'learning_rate': 0.001, 'neurons_layer1': 256, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7671\n",
      "üìà √âpoques: 55\n",
      "‚è±Ô∏è Temps: 109.8s\n",
      "\n",
      "üß™ Test 93/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 32, 'dropout_rate1': 0.4, 'dropout_rate2': 0.5, 'learning_rate': 0.002, 'neurons_layer1': 128, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7666\n",
      "üìà √âpoques: 42\n",
      "‚è±Ô∏è Temps: 90.4s\n",
      "\n",
      "üß™ Test 94/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 32, 'dropout_rate1': 0.4, 'dropout_rate2': 0.5, 'learning_rate': 0.002, 'neurons_layer1': 128, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7701\n",
      "üìà √âpoques: 52\n",
      "‚è±Ô∏è Temps: 114.8s\n",
      "\n",
      "üß™ Test 95/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 32, 'dropout_rate1': 0.4, 'dropout_rate2': 0.5, 'learning_rate': 0.002, 'neurons_layer1': 256, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7697\n",
      "üìà √âpoques: 52\n",
      "‚è±Ô∏è Temps: 113.0s\n",
      "\n",
      "üß™ Test 96/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 32, 'dropout_rate1': 0.4, 'dropout_rate2': 0.5, 'learning_rate': 0.002, 'neurons_layer1': 256, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7644\n",
      "üìà √âpoques: 34\n",
      "‚è±Ô∏è Temps: 54.7s\n",
      "\n",
      "üß™ Test 97/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 64, 'dropout_rate1': 0.3, 'dropout_rate2': 0.4, 'learning_rate': 0.001, 'neurons_layer1': 128, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7668\n",
      "üìà √âpoques: 51\n",
      "‚è±Ô∏è Temps: 33.5s\n",
      "\n",
      "üß™ Test 98/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 64, 'dropout_rate1': 0.3, 'dropout_rate2': 0.4, 'learning_rate': 0.001, 'neurons_layer1': 128, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7687\n",
      "üìà √âpoques: 58\n",
      "‚è±Ô∏è Temps: 59.9s\n",
      "\n",
      "üß™ Test 99/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 64, 'dropout_rate1': 0.3, 'dropout_rate2': 0.4, 'learning_rate': 0.001, 'neurons_layer1': 256, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7644\n",
      "üìà √âpoques: 58\n",
      "‚è±Ô∏è Temps: 47.6s\n",
      "\n",
      "üß™ Test 100/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 64, 'dropout_rate1': 0.3, 'dropout_rate2': 0.4, 'learning_rate': 0.001, 'neurons_layer1': 256, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7679\n",
      "üìà √âpoques: 48\n",
      "‚è±Ô∏è Temps: 41.2s\n",
      "\n",
      "üß™ Test 101/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 64, 'dropout_rate1': 0.3, 'dropout_rate2': 0.4, 'learning_rate': 0.002, 'neurons_layer1': 128, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7693\n",
      "üìà √âpoques: 54\n",
      "‚è±Ô∏è Temps: 71.1s\n",
      "\n",
      "üß™ Test 102/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 64, 'dropout_rate1': 0.3, 'dropout_rate2': 0.4, 'learning_rate': 0.002, 'neurons_layer1': 128, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7677\n",
      "üìà √âpoques: 54\n",
      "‚è±Ô∏è Temps: 78.0s\n",
      "\n",
      "üß™ Test 103/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 64, 'dropout_rate1': 0.3, 'dropout_rate2': 0.4, 'learning_rate': 0.002, 'neurons_layer1': 256, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7701\n",
      "üìà √âpoques: 44\n",
      "‚è±Ô∏è Temps: 34.9s\n",
      "\n",
      "üß™ Test 104/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 64, 'dropout_rate1': 0.3, 'dropout_rate2': 0.4, 'learning_rate': 0.002, 'neurons_layer1': 256, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7668\n",
      "üìà √âpoques: 42\n",
      "‚è±Ô∏è Temps: 66.1s\n",
      "\n",
      "üß™ Test 105/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 64, 'dropout_rate1': 0.3, 'dropout_rate2': 0.5, 'learning_rate': 0.001, 'neurons_layer1': 128, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7701\n",
      "üìà √âpoques: 74\n",
      "‚è±Ô∏è Temps: 102.5s\n",
      "\n",
      "üß™ Test 106/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 64, 'dropout_rate1': 0.3, 'dropout_rate2': 0.5, 'learning_rate': 0.001, 'neurons_layer1': 128, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7662\n",
      "üìà √âpoques: 90\n",
      "‚è±Ô∏è Temps: 113.9s\n",
      "\n",
      "üß™ Test 107/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 64, 'dropout_rate1': 0.3, 'dropout_rate2': 0.5, 'learning_rate': 0.001, 'neurons_layer1': 256, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7666\n",
      "üìà √âpoques: 71\n",
      "‚è±Ô∏è Temps: 52.9s\n",
      "\n",
      "üß™ Test 108/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 64, 'dropout_rate1': 0.3, 'dropout_rate2': 0.5, 'learning_rate': 0.001, 'neurons_layer1': 256, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7689\n",
      "üìà √âpoques: 71\n",
      "‚è±Ô∏è Temps: 78.4s\n",
      "\n",
      "üß™ Test 109/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 64, 'dropout_rate1': 0.3, 'dropout_rate2': 0.5, 'learning_rate': 0.002, 'neurons_layer1': 128, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7683\n",
      "üìà √âpoques: 44\n",
      "‚è±Ô∏è Temps: 32.6s\n",
      "\n",
      "üß™ Test 110/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 64, 'dropout_rate1': 0.3, 'dropout_rate2': 0.5, 'learning_rate': 0.002, 'neurons_layer1': 128, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7683\n",
      "üìà √âpoques: 54\n",
      "‚è±Ô∏è Temps: 40.5s\n",
      "\n",
      "üß™ Test 111/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 64, 'dropout_rate1': 0.3, 'dropout_rate2': 0.5, 'learning_rate': 0.002, 'neurons_layer1': 256, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7679\n",
      "üìà √âpoques: 40\n",
      "‚è±Ô∏è Temps: 30.2s\n",
      "\n",
      "üß™ Test 112/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 64, 'dropout_rate1': 0.3, 'dropout_rate2': 0.5, 'learning_rate': 0.002, 'neurons_layer1': 256, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7689\n",
      "üìà √âpoques: 64\n",
      "‚è±Ô∏è Temps: 50.7s\n",
      "\n",
      "üß™ Test 113/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 64, 'dropout_rate1': 0.4, 'dropout_rate2': 0.4, 'learning_rate': 0.001, 'neurons_layer1': 128, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7671\n",
      "üìà √âpoques: 65\n",
      "‚è±Ô∏è Temps: 48.8s\n",
      "\n",
      "üß™ Test 114/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 64, 'dropout_rate1': 0.4, 'dropout_rate2': 0.4, 'learning_rate': 0.001, 'neurons_layer1': 128, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7664\n",
      "üìà √âpoques: 56\n",
      "‚è±Ô∏è Temps: 78.5s\n",
      "\n",
      "üß™ Test 115/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 64, 'dropout_rate1': 0.4, 'dropout_rate2': 0.4, 'learning_rate': 0.001, 'neurons_layer1': 256, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7664\n",
      "üìà √âpoques: 66\n",
      "‚è±Ô∏è Temps: 93.2s\n",
      "\n",
      "üß™ Test 116/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 64, 'dropout_rate1': 0.4, 'dropout_rate2': 0.4, 'learning_rate': 0.001, 'neurons_layer1': 256, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7687\n",
      "üìà √âpoques: 76\n",
      "‚è±Ô∏è Temps: 67.9s\n",
      "\n",
      "üß™ Test 117/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 64, 'dropout_rate1': 0.4, 'dropout_rate2': 0.4, 'learning_rate': 0.002, 'neurons_layer1': 128, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7689\n",
      "üìà √âpoques: 56\n",
      "‚è±Ô∏è Temps: 37.8s\n",
      "\n",
      "üß™ Test 118/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 64, 'dropout_rate1': 0.4, 'dropout_rate2': 0.4, 'learning_rate': 0.002, 'neurons_layer1': 128, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7681\n",
      "üìà √âpoques: 50\n",
      "‚è±Ô∏è Temps: 43.0s\n",
      "\n",
      "üß™ Test 119/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 64, 'dropout_rate1': 0.4, 'dropout_rate2': 0.4, 'learning_rate': 0.002, 'neurons_layer1': 256, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7681\n",
      "üìà √âpoques: 48\n",
      "‚è±Ô∏è Temps: 66.1s\n",
      "\n",
      "üß™ Test 120/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 64, 'dropout_rate1': 0.4, 'dropout_rate2': 0.4, 'learning_rate': 0.002, 'neurons_layer1': 256, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7695\n",
      "üìà √âpoques: 39\n",
      "‚è±Ô∏è Temps: 49.9s\n",
      "\n",
      "üß™ Test 121/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 64, 'dropout_rate1': 0.4, 'dropout_rate2': 0.5, 'learning_rate': 0.001, 'neurons_layer1': 128, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7681\n",
      "üìà √âpoques: 57\n",
      "‚è±Ô∏è Temps: 64.3s\n",
      "\n",
      "üß™ Test 122/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 64, 'dropout_rate1': 0.4, 'dropout_rate2': 0.5, 'learning_rate': 0.001, 'neurons_layer1': 128, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7668\n",
      "üìà √âpoques: 70\n",
      "‚è±Ô∏è Temps: 51.9s\n",
      "\n",
      "üß™ Test 123/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 64, 'dropout_rate1': 0.4, 'dropout_rate2': 0.5, 'learning_rate': 0.001, 'neurons_layer1': 256, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7709\n",
      "üìà √âpoques: 55\n",
      "‚è±Ô∏è Temps: 76.3s\n",
      "\n",
      "üß™ Test 124/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 64, 'dropout_rate1': 0.4, 'dropout_rate2': 0.5, 'learning_rate': 0.001, 'neurons_layer1': 256, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7685\n",
      "üìà √âpoques: 58\n",
      "‚è±Ô∏è Temps: 92.4s\n",
      "\n",
      "üß™ Test 125/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 64, 'dropout_rate1': 0.4, 'dropout_rate2': 0.5, 'learning_rate': 0.002, 'neurons_layer1': 128, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7668\n",
      "üìà √âpoques: 43\n",
      "‚è±Ô∏è Temps: 40.3s\n",
      "\n",
      "üß™ Test 126/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 64, 'dropout_rate1': 0.4, 'dropout_rate2': 0.5, 'learning_rate': 0.002, 'neurons_layer1': 128, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7675\n",
      "üìà √âpoques: 51\n",
      "‚è±Ô∏è Temps: 48.8s\n",
      "\n",
      "üß™ Test 127/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 64, 'dropout_rate1': 0.4, 'dropout_rate2': 0.5, 'learning_rate': 0.002, 'neurons_layer1': 256, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7675\n",
      "üìà √âpoques: 59\n",
      "‚è±Ô∏è Temps: 51.9s\n",
      "\n",
      "üß™ Test 128/128\n",
      "‚öôÔ∏è Param√®tres: {'activation': 'elu', 'batch_size': 64, 'dropout_rate1': 0.4, 'dropout_rate2': 0.5, 'learning_rate': 0.002, 'neurons_layer1': 256, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "üìä Pr√©cision: 0.7685\n",
      "üìà √âpoques: 60\n",
      "‚è±Ô∏è Temps: 49.1s\n",
      "\n",
      "üìä ANALYSE D√âTAILL√âE DES R√âSULTATS\n",
      "==================================================\n",
      "‚úÖ Tests r√©ussis: 128/133\n",
      "üèÜ Meilleure pr√©cision: 0.7798\n",
      "üìà Pr√©cision moyenne: 0.7690\n",
      "üìä √âcart-type: 0.0030\n",
      "üìâ Pr√©cision minimale: 0.7620\n",
      "\n",
      "üèÖ TOP 5 DES MEILLEURES CONFIGURATIONS:\n",
      "----------------------------------------\n",
      "\n",
      "1. Pr√©cision: 0.7798\n",
      "   Param√®tres: {'activation': 'relu', 'batch_size': 64, 'dropout_rate1': 0.3, 'dropout_rate2': 0.4, 'learning_rate': 0.001, 'neurons_layer1': 256, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "   √âpoques: 49\n",
      "\n",
      "2. Pr√©cision: 0.7776\n",
      "   Param√®tres: {'activation': 'relu', 'batch_size': 64, 'dropout_rate1': 0.4, 'dropout_rate2': 0.5, 'learning_rate': 0.002, 'neurons_layer1': 256, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "   √âpoques: 48\n",
      "\n",
      "3. Pr√©cision: 0.7756\n",
      "   Param√®tres: {'activation': 'relu', 'batch_size': 64, 'dropout_rate1': 0.4, 'dropout_rate2': 0.4, 'learning_rate': 0.002, 'neurons_layer1': 256, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "   √âpoques: 40\n",
      "\n",
      "4. Pr√©cision: 0.7745\n",
      "   Param√®tres: {'activation': 'relu', 'batch_size': 64, 'dropout_rate1': 0.4, 'dropout_rate2': 0.5, 'learning_rate': 0.002, 'neurons_layer1': 128, 'neurons_layer2': 64, 'optimizer_type': 'adam'}\n",
      "   √âpoques: 70\n",
      "\n",
      "5. Pr√©cision: 0.7743\n",
      "   Param√®tres: {'activation': 'relu', 'batch_size': 32, 'dropout_rate1': 0.3, 'dropout_rate2': 0.5, 'learning_rate': 0.002, 'neurons_layer1': 256, 'neurons_layer2': 128, 'optimizer_type': 'adam'}\n",
      "   √âpoques: 37\n",
      "\n",
      "üéØ ANALYSE DES PARAM√àTRES OPTIMAUX:\n",
      "----------------------------------------\n",
      "Meilleure configuration:\n",
      "   activation: relu\n",
      "   batch_size: 64\n",
      "   dropout_rate1: 0.3\n",
      "   dropout_rate2: 0.4\n",
      "   learning_rate: 0.001\n",
      "   neurons_layer1: 256\n",
      "   neurons_layer2: 64\n",
      "   optimizer_type: adam\n",
      "\n",
      "üéØ √âVALUATION FINALE: Optimized_TFIDF_SPARSE\n",
      "==================================================\n",
      "üèÜ PR√âCISION FINALE: 0.7798\n",
      "\n",
      "üìä RAPPORT D√âTAILL√â:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Classe_0       0.71      0.79      0.75      1631\n",
      "    Classe_1       0.81      0.73      0.77      1672\n",
      "    Classe_2       0.83      0.82      0.83      1638\n",
      "\n",
      "    accuracy                           0.78      4941\n",
      "   macro avg       0.78      0.78      0.78      4941\n",
      "weighted avg       0.78      0.78      0.78      4941\n",
      "\n",
      "\n",
      "üîç MATRICE DE CONFUSION:\n",
      "[[1286  192  153]\n",
      " [ 325 1220  127]\n",
      " [ 200   91 1347]]\n",
      "\n",
      "üìà AM√âLIORATION:\n",
      "   Score original: 0.7648\n",
      "   Score optimis√©: 0.7798\n",
      "   Am√©lioration: +0.0150 (+1.96%)\n",
      "\n",
      "‚úÖ OPTIMISATION TERMIN√âE!\n",
      "üèÜ Am√©lioration de la pr√©cision: 0.7648 ‚Üí 0.7798\n"
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "# OPTIMISATION DU MEILLEUR MOD√àLE: TFIDF + SPARSE\n",
    "# =============================================================\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "import time\n",
    "\n",
    "print(\"\\nüèÜ OPTIMISATION DU MEILLEUR MOD√àLE: TFIDF + SPARSE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# =============================================================\n",
    "# CONFIGURATION DES PARAM√àTRES √Ä TESTER\n",
    "# =============================================================\n",
    "\n",
    "# Param√®tres sp√©cifiques pour le mod√®le SPARSE\n",
    "param_grid = {\n",
    "    # Architecture du r√©seau\n",
    "    'neurons_layer1': [64, 128, 256],\n",
    "    'neurons_layer2': [32, 64, 128],\n",
    "    'neurons_layer3': [16, 32, 64],  # Couche suppl√©mentaire\n",
    "    \n",
    "    # R√©gularisation\n",
    "    'dropout_rate1': [0.2, 0.3, 0.4],\n",
    "    'dropout_rate2': [0.3, 0.4, 0.5],\n",
    "    \n",
    "    # Optimisation\n",
    "    'learning_rate': [0.0005, 0.001, 0.002, 0.005],\n",
    "    'optimizer_type': ['adam', 'rmsprop'],\n",
    "    \n",
    "    # Entra√Ænement\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'patience': [15, 20, 25],\n",
    "    \n",
    "    # Activation\n",
    "    'activation': ['relu', 'elu', 'swish']\n",
    "}\n",
    "\n",
    "# Configuration rapide pour tests initiaux\n",
    "quick_param_grid = {\n",
    "    'neurons_layer1': [128, 256],\n",
    "    'neurons_layer2': [64, 128],\n",
    "    'dropout_rate1': [0.3, 0.4],\n",
    "    'dropout_rate2': [0.4, 0.5],\n",
    "    'learning_rate': [0.001, 0.002],\n",
    "    'optimizer_type': ['adam'],\n",
    "    'batch_size': [32, 64],\n",
    "    'activation': ['relu', 'elu']\n",
    "}\n",
    "\n",
    "# =============================================================\n",
    "# FONCTION DE CR√âATION DU MOD√àLE OPTIMIS√â\n",
    "# =============================================================\n",
    "\n",
    "def create_optimized_sparse_model(input_dim, num_classes, **params):\n",
    "    \"\"\"\n",
    "    Cr√©e un mod√®le SPARSE optimis√© avec les param√®tres donn√©s\n",
    "    \"\"\"\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "    from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "    from tensorflow.keras.regularizers import l1_l2\n",
    "    \n",
    "    # Param√®tres par d√©faut\n",
    "    neurons_layer1 = params.get('neurons_layer1', 128)\n",
    "    neurons_layer2 = params.get('neurons_layer2', 64)\n",
    "    neurons_layer3 = params.get('neurons_layer3', 32)\n",
    "    dropout_rate1 = params.get('dropout_rate1', 0.3)\n",
    "    dropout_rate2 = params.get('dropout_rate2', 0.4)\n",
    "    learning_rate = params.get('learning_rate', 0.001)\n",
    "    optimizer_type = params.get('optimizer_type', 'adam')\n",
    "    activation = params.get('activation', 'relu')\n",
    "    \n",
    "    # Construction du mod√®le\n",
    "    model = Sequential([\n",
    "        # Couche d'entr√©e avec BatchNorm\n",
    "        Dense(neurons_layer1, activation=activation, input_shape=(input_dim,),\n",
    "              kernel_regularizer=l1_l2(l1=1e-6, l2=1e-4)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout_rate1),\n",
    "        \n",
    "        # Couche cach√©e 1\n",
    "        Dense(neurons_layer2, activation=activation,\n",
    "              kernel_regularizer=l1_l2(l1=1e-6, l2=1e-4)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout_rate2),\n",
    "        \n",
    "        # Couche cach√©e 2 (optionnelle)\n",
    "        Dense(neurons_layer3, activation=activation,\n",
    "              kernel_regularizer=l1_l2(l1=1e-6, l2=1e-4)),\n",
    "        Dropout(dropout_rate2),\n",
    "        \n",
    "        # Couche de sortie\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ], name=f\"OptimizedSparse_{neurons_layer1}_{neurons_layer2}_{neurons_layer3}\")\n",
    "    \n",
    "    # Choix de l'optimiseur\n",
    "    if optimizer_type == 'adam':\n",
    "        optimizer = Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999)\n",
    "    elif optimizer_type == 'rmsprop':\n",
    "        optimizer = RMSprop(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    # Compilation\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# =============================================================\n",
    "# GRIDSEARCH POUR LE MEILLEUR MOD√àLE\n",
    "# =============================================================\n",
    "\n",
    "def optimize_best_model(use_quick_search=True):\n",
    "    \"\"\"\n",
    "    Optimise le meilleur mod√®le (TFIDF + SPARSE)\n",
    "    \"\"\"\n",
    "    print(f\"\\nüîç LANCEMENT DE L'OPTIMISATION\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # S√©lection du grid de param√®tres\n",
    "    current_param_grid = quick_param_grid if use_quick_search else param_grid\n",
    "    param_combinations = list(ParameterGrid(current_param_grid))\n",
    "    \n",
    "    print(f\"üìä Nombre de combinaisons √† tester: {len(param_combinations)}\")\n",
    "    print(f\"‚è±Ô∏è Temps estim√©: {len(param_combinations) * 2:.0f} minutes\")\n",
    "    \n",
    "    # R√©cup√©ration des donn√©es du meilleur mod√®le (TFIDF)\n",
    "    X_train_best, X_test_best = lsa_vectors['tfidf']  # Ajustez selon votre nomenclature\n",
    "    \n",
    "    # Variables pour tracking\n",
    "    best_accuracy = 0\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    best_history = None\n",
    "    results_log = []\n",
    "    \n",
    "    print(f\"\\nüöÄ D√âBUT DES TESTS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for i, params in enumerate(param_combinations):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        print(f\"\\nüß™ Test {i+1}/{len(param_combinations)}\")\n",
    "        print(f\"‚öôÔ∏è Param√®tres: {params}\")\n",
    "        \n",
    "        try:\n",
    "            # Cr√©ation du mod√®le\n",
    "            model = create_optimized_sparse_model(\n",
    "                X_train_best.shape[1], \n",
    "                num_classes, \n",
    "                **params\n",
    "            )\n",
    "            \n",
    "            # Callbacks personnalis√©s\n",
    "            early_stopping = EarlyStopping(\n",
    "                monitor='val_accuracy',\n",
    "                patience=params.get('patience', 20),\n",
    "                restore_best_weights=True,\n",
    "                verbose=0\n",
    "            )\n",
    "            \n",
    "            reduce_lr = ReduceLROnPlateau(\n",
    "                monitor='val_loss',\n",
    "                factor=0.3,\n",
    "                patience=7,\n",
    "                min_lr=0.00001,\n",
    "                verbose=0\n",
    "            )\n",
    "            \n",
    "            # Entra√Ænement\n",
    "            history = model.fit(\n",
    "                X_train_best, y_train_categorical,\n",
    "                validation_data=(X_test_best, y_test_categorical),\n",
    "                epochs=100,\n",
    "                batch_size=params.get('batch_size', 32),\n",
    "                callbacks=[early_stopping, reduce_lr],\n",
    "                verbose=0\n",
    "            )\n",
    "            \n",
    "            # √âvaluation\n",
    "            y_pred = model.predict(X_test_best, verbose=0)\n",
    "            y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "            accuracy = accuracy_score(y_test_encoded, y_pred_classes)\n",
    "            \n",
    "            # Temps d'ex√©cution\n",
    "            execution_time = time.time() - start_time\n",
    "            \n",
    "            # Log des r√©sultats\n",
    "            result = {\n",
    "                'test_number': i + 1,\n",
    "                'params': params.copy(),\n",
    "                'accuracy': accuracy,\n",
    "                'epochs_trained': len(history.history['loss']),\n",
    "                'execution_time': execution_time,\n",
    "                'val_loss': min(history.history['val_loss']),\n",
    "                'val_accuracy': max(history.history['val_accuracy'])\n",
    "            }\n",
    "            results_log.append(result)\n",
    "            \n",
    "            print(f\"üìä Pr√©cision: {accuracy:.4f}\")\n",
    "            print(f\"üìà √âpoques: {len(history.history['loss'])}\")\n",
    "            print(f\"‚è±Ô∏è Temps: {execution_time:.1f}s\")\n",
    "            \n",
    "            # Mise √† jour du meilleur mod√®le\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_params = params.copy()\n",
    "                best_model = model\n",
    "                best_history = history\n",
    "                print(f\"üèÜ NOUVEAU RECORD! Pr√©cision: {accuracy:.4f}\")\n",
    "                \n",
    "                # Sauvegarde imm√©diate du meilleur mod√®le\n",
    "                model.save_weights(f'best_model_weights_{accuracy:.4f}.h5')\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erreur: {str(e)}\")\n",
    "            results_log.append({\n",
    "                'test_number': i + 1,\n",
    "                'params': params.copy(),\n",
    "                'accuracy': 0,\n",
    "                'error': str(e)\n",
    "            })\n",
    "            continue\n",
    "    \n",
    "    return best_model, best_params, best_accuracy, best_history, results_log\n",
    "\n",
    "# =============================================================\n",
    "# ANALYSE D√âTAILL√âE DES R√âSULTATS\n",
    "# =============================================================\n",
    "\n",
    "def analyze_optimization_results(results_log, best_params, best_accuracy):\n",
    "    \"\"\"\n",
    "    Analyse d√©taill√©e des r√©sultats d'optimisation\n",
    "    \"\"\"\n",
    "    print(f\"\\nüìä ANALYSE D√âTAILL√âE DES R√âSULTATS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Statistiques g√©n√©rales\n",
    "    successful_tests = [r for r in results_log if 'error' not in r]\n",
    "    accuracies = [r['accuracy'] for r in successful_tests]\n",
    "    \n",
    "    print(f\"‚úÖ Tests r√©ussis: {len(successful_tests)}/{len(results_log)}\")\n",
    "    print(f\"üèÜ Meilleure pr√©cision: {best_accuracy:.4f}\")\n",
    "    print(f\"üìà Pr√©cision moyenne: {np.mean(accuracies):.4f}\")\n",
    "    print(f\"üìä √âcart-type: {np.std(accuracies):.4f}\")\n",
    "    print(f\"üìâ Pr√©cision minimale: {min(accuracies):.4f}\")\n",
    "    \n",
    "    # Top 5 des meilleures configurations\n",
    "    print(f\"\\nüèÖ TOP 5 DES MEILLEURES CONFIGURATIONS:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    sorted_results = sorted(successful_tests, key=lambda x: x['accuracy'], reverse=True)\n",
    "    for i, result in enumerate(sorted_results[:5]):\n",
    "        print(f\"\\n{i+1}. Pr√©cision: {result['accuracy']:.4f}\")\n",
    "        print(f\"   Param√®tres: {result['params']}\")\n",
    "        print(f\"   √âpoques: {result['epochs_trained']}\")\n",
    "    \n",
    "    # Analyse des param√®tres les plus performants\n",
    "    print(f\"\\nüéØ ANALYSE DES PARAM√àTRES OPTIMAUX:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Meilleure configuration:\")\n",
    "    for key, value in best_params.items():\n",
    "        print(f\"   {key}: {value}\")\n",
    "    \n",
    "    return sorted_results\n",
    "\n",
    "# =============================================================\n",
    "# √âVALUATION FINALE DU MOD√àLE OPTIMIS√â\n",
    "# =============================================================\n",
    "\n",
    "def final_evaluation(best_model, model_name=\"Optimized_TFIDF_SPARSE\"):\n",
    "    \"\"\"\n",
    "    √âvaluation finale compl√®te du mod√®le optimis√©\n",
    "    \"\"\"\n",
    "    print(f\"\\nüéØ √âVALUATION FINALE: {model_name}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # R√©cup√©ration des donn√©es\n",
    "    X_train_best, X_test_best = lsa_vectors['tfidf']\n",
    "    \n",
    "    # Pr√©dictions\n",
    "    y_pred = best_model.predict(X_test_best, verbose=0)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    \n",
    "    # M√©triques d√©taill√©es\n",
    "    accuracy = accuracy_score(y_test_encoded, y_pred_classes)\n",
    "    report = classification_report(y_test_encoded, y_pred_classes, \n",
    "                                 target_names=[f'Classe_{i}' for i in range(num_classes)])\n",
    "    \n",
    "    print(f\"üèÜ PR√âCISION FINALE: {accuracy:.4f}\")\n",
    "    print(f\"\\nüìä RAPPORT D√âTAILL√â:\")\n",
    "    print(report)\n",
    "    \n",
    "    # Matrice de confusion\n",
    "    cm = confusion_matrix(y_test_encoded, y_pred_classes)\n",
    "    print(f\"\\nüîç MATRICE DE CONFUSION:\")\n",
    "    print(cm)\n",
    "    \n",
    "    # Am√©lioration par rapport au mod√®le original\n",
    "    original_accuracy = 0.7648  # Votre meilleur score original\n",
    "    improvement = accuracy - original_accuracy\n",
    "    improvement_percent = (improvement / original_accuracy) * 100\n",
    "    \n",
    "    print(f\"\\nüìà AM√âLIORATION:\")\n",
    "    print(f\"   Score original: {original_accuracy:.4f}\")\n",
    "    print(f\"   Score optimis√©: {accuracy:.4f}\")\n",
    "    print(f\"   Am√©lioration: {improvement:+.4f} ({improvement_percent:+.2f}%)\")\n",
    "    \n",
    "    return accuracy, report\n",
    "\n",
    "# =============================================================\n",
    "# EX√âCUTION DE L'OPTIMISATION\n",
    "# =============================================================\n",
    "\n",
    "print(\"\\nüöÄ LANCEMENT DE L'OPTIMISATION DU MEILLEUR MOD√àLE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Choix du type de recherche\n",
    "USE_QUICK_SEARCH = True  # Changez en False pour une recherche compl√®te\n",
    "\n",
    "print(f\"üîç Mode: {'Recherche rapide' if USE_QUICK_SEARCH else 'Recherche compl√®te'}\")\n",
    "\n",
    "# Lancement de l'optimisation\n",
    "best_model, best_params, best_accuracy, best_history, results_log = optimize_best_model(USE_QUICK_SEARCH)\n",
    "\n",
    "# Analyse des r√©sultats\n",
    "if best_model is not None:\n",
    "    sorted_results = analyze_optimization_results(results_log, best_params, best_accuracy)\n",
    "    \n",
    "    # √âvaluation finale\n",
    "    final_accuracy, final_report = final_evaluation(best_model)\n",
    "    \n",
    "    print(f\"\\n‚úÖ OPTIMISATION TERMIN√âE!\")\n",
    "    print(f\"üèÜ Am√©lioration de la pr√©cision: {0.7648:.4f} ‚Üí {final_accuracy:.4f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Aucune optimisation r√©ussie. V√©rifiez vos donn√©es et param√®tres.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d6442aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Sequential name=OptimizedSparse_256_64_32, built=True>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8770f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b238706",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ SAUVEGARDE DU MOD√àLE OPTIMIS√â\n",
      "----------------------------------------\n",
      "‚úÖ Mod√®le sauvegard√©: best_optimized_model_0.7798.h5\n",
      "‚úÖ Param√®tres sauvegard√©s: best_params_0.7798.json\n"
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "# SAUVEGARDE DU MOD√àLE OPTIMIS√â\n",
    "# =============================================================\n",
    "\n",
    "if best_model is not None:\n",
    "    print(f\"\\nüíæ SAUVEGARDE DU MOD√àLE OPTIMIS√â\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Sauvegarde du mod√®le complet\n",
    "    best_model.save(f'best_optimized_model_{best_accuracy:.4f}.h5')\n",
    "    \n",
    "    # Sauvegarde des param√®tres\n",
    "    import json\n",
    "    with open(f'best_params_{best_accuracy:.4f}.json', 'w') as f:\n",
    "        json.dump(best_params, f, indent=2)\n",
    "    \n",
    "    print(f\"‚úÖ Mod√®le sauvegard√©: best_optimized_model_{best_accuracy:.4f}.h5\")\n",
    "    print(f\"‚úÖ Param√®tres sauvegard√©s: best_params_{best_accuracy:.4f}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41de5a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Mod√®le charg√© avec succ√®s !\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_171\" is incompatible with the layer: expected axis -1 of input shape to have value 100, but received input with shape (32, 5652)\u001b[0m\n\nArguments received by Sequential.call():\n  ‚Ä¢ inputs=tf.Tensor(shape=(32, 5652), dtype=float32)\n  ‚Ä¢ training=False\n  ‚Ä¢ mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ Mod√®le charg√© avec succ√®s !\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# üìä Pr√©dictions (avec TF-IDF ici, mais tu peux changer par glove, w2v, bert...)\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m y_pred_prob \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test_tfidf)\n\u001b[0;32m     17\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(y_pred_prob, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Si softmax en sortie\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# üìã Matrice de confusion\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hp\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\hp\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\input_spec.py:227\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis, value \u001b[38;5;129;01min\u001b[39;00m spec\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape[axis] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[0;32m    224\u001b[0m             value,\n\u001b[0;32m    225\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    226\u001b[0m         }:\n\u001b[1;32m--> 227\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    228\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    229\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: expected axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    230\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof input shape to have value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    231\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut received input with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    232\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    233\u001b[0m             )\n\u001b[0;32m    234\u001b[0m \u001b[38;5;66;03m# Check shape.\u001b[39;00m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_171\" is incompatible with the layer: expected axis -1 of input shape to have value 100, but received input with shape (32, 5652)\u001b[0m\n\nArguments received by Sequential.call():\n  ‚Ä¢ inputs=tf.Tensor(shape=(32, 5652), dtype=float32)\n  ‚Ä¢ training=False\n  ‚Ä¢ mask=None"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "\n",
    "X_test_tfidf = joblib.load(base + \"/X_test_tfidf.pkl\")\n",
    "y_test = joblib.load(base + \"/y_test.pkl\")\n",
    "\n",
    "# üì• Charger le mod√®le optimis√©\n",
    "model = load_model(r\"C:\\Users\\hp\\Desktop\\pfemaster\\NOOTBOOK\\best_optimized_model_0.7798.h5\")\n",
    "print(\"‚úÖ Mod√®le charg√© avec succ√®s !\")\n",
    "\n",
    "# üìä Pr√©dictions (avec TF-IDF ici, mais tu peux changer par glove, w2v, bert...)\n",
    "y_pred_prob = model.predict(X_test_tfidf)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)  # Si softmax en sortie\n",
    "\n",
    "# üìã Matrice de confusion\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nüìä Matrice de confusion :\\n\", cm)\n",
    "\n",
    "# üé® Affichage graphique\n",
    "plt.figure(figsize=(8, 6))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Alg√©rien', 'Marocain', 'Tunisien'])\n",
    "disp.plot(cmap='Blues', values_format='d')\n",
    "plt.title(\"Matrice de Confusion - Mod√®le Optimis√© (TF-IDF)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96013b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m155/155\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "\n",
      "üìä Matrice de confusion (TF-IDF LSA) :\n",
      " [[1286  192  153]\n",
      " [ 325 1220  127]\n",
      " [ 200   91 1347]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Exemple : test sur TF-IDF apr√®s LSA\n",
    "X_test_lsa = lsa_vectors['tfidf'][1]  # Test set LSA\n",
    "y_test = joblib.load(base + \"/y_test.pkl\")\n",
    "\n",
    "# Charger mod√®le optimis√© entra√Æn√© avec LSA-TFIDF\n",
    "model = load_model(r\"C:\\Users\\hp\\Desktop\\pfemaster\\NOOTBOOK\\best_optimized_model_0.7798.h5\")\n",
    "\n",
    "# Pr√©diction\n",
    "y_pred_prob = model.predict(X_test_lsa)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Matrice de confusion\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nüìä Matrice de confusion (TF-IDF LSA) :\\n\", cm)\n",
    "\n",
    "# Affichage graphique\n",
    "plt.figure(figsize=(8, 6))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Alg√©rien', 'Marocain', 'Tunisien'])\n",
    "disp.plot(cmap='Blues', values_format='d')\n",
    "plt.title(\"Matrice de Confusion - Mod√®le Optimis√© (TF-IDF + LSA)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec98b28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Test du mod√®le sur vecteur : TFIDF + LSA\n",
      "‚úÖ Mod√®le charg√© avec succ√®s !\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "\n",
      "üìä Matrice de confusion :\n",
      " [[1286  192  153]\n",
      " [ 325 1220  127]\n",
      " [ 200   91 1347]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã Rapport de classification :\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Alg√©rien       0.71      0.79      0.75      1631\n",
      "    Marocain       0.81      0.73      0.77      1672\n",
      "    Tunisien       0.83      0.82      0.83      1638\n",
      "\n",
      "    accuracy                           0.78      4941\n",
      "   macro avg       0.78      0.78      0.78      4941\n",
      "weighted avg       0.78      0.78      0.78      4941\n",
      "\n",
      "\n",
      "üéØ Accuracy globale : 0.7798\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# üì• Charger y_test\n",
    "y_test = joblib.load(base + \"/y_test.pkl\")\n",
    "\n",
    "# üì• Choisir le vecteur LSA\n",
    "vector_name = 'tfidf'  # Change ici : 'glove', 'w2v', 'bert', 'bert_2' si besoin\n",
    "X_test_lsa = lsa_vectors[vector_name][1]\n",
    "\n",
    "print(f\"üîç Test du mod√®le sur vecteur : {vector_name.upper()} + LSA\")\n",
    "\n",
    "# üì• Charger mod√®le optimis√©\n",
    "model = load_model(r\"C:\\Users\\hp\\Desktop\\pfemaster\\NOOTBOOK\\best_optimized_model_0.7798.h5\")\n",
    "print(\"‚úÖ Mod√®le charg√© avec succ√®s !\")\n",
    "\n",
    "# üìä Pr√©diction\n",
    "y_pred_prob = model.predict(X_test_lsa)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# üìä Matrice de confusion\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nüìä Matrice de confusion :\\n\", cm)\n",
    "\n",
    "# üé® Affichage graphique\n",
    "plt.figure(figsize=(8, 6))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Alg√©rien', 'Marocain', 'Tunisien'])\n",
    "disp.plot(cmap='Blues', values_format='d')\n",
    "plt.title(f\"Matrice de Confusion - Mod√®le Optimis√© ({vector_name.upper()} + LSA)\")\n",
    "plt.show()\n",
    "\n",
    "# ‚úÖ M√©triques d√©taill√©es\n",
    "print(\"\\nüìã Rapport de classification :\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Alg√©rien', 'Marocain', 'Tunisien']))\n",
    "\n",
    "# ‚úÖ Accuracy globale\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nüéØ Accuracy globale : {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b276ec52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
